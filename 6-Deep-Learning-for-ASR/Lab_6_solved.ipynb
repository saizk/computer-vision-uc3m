{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bG5FMg3iJ9KF"
   },
   "source": [
    "![uc3m](http://materplat.org/wp-content/uploads/LogoUC3M.jpg)\n",
    "\n",
    "## Sergio Aizcorbe (100406602)\n",
    "## Bernardo Bouzas (100406634)\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### Mount Google Drive, install dependencies and download the database. Since the database will take up to 10 minutes to download, continue reading the next sections.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2KVIyST72TCZ"
   },
   "outputs": [],
   "source": [
    "# Load the Drive helper and mount\n",
    "#from google.colab import drive\n",
    "\n",
    "# This will prompt for authorization.\n",
    "#drive.mount('/content/drive')\n",
    "\n",
    "# Create a new folder in your drive and change to that directory as: \n",
    "# /content/drive/My_Drive/new_dir_that_you_just_created_for_this_lab\n",
    "#import os\n",
    "#os.chdir('/content/drive/My Drive/TAVVA/2021-22/Labs/L7-ASR with Deep Learning')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XTgpbDaEz75Z",
    "outputId": "22be5de3-7b44-4559-e668-ce09a6eabe8d"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Collecting pydub\n",
      "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
      "Installing collected packages: pydub\n",
      "Successfully installed pydub-0.25.1\n"
     ]
    }
   ],
   "source": [
    "!pip install pydub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 100,
     "referenced_widgets": [
      "d37d7201fc334f7ba2676f1f59dd4ad8",
      "315ce3326a34491ba50591a79a0a10ff",
      "412dbe9081924145ba9950f07e4e7dea",
      "dfa664d9b2c740cf838c422d569a44c3",
      "70fca4038c1b4f9a9d572f6626a6d30a",
      "8f686644fae946888b53f4a8d03edde1",
      "afc4af15e9f24f0085ee5ebc40bd63ae",
      "2137b72ece444e8ea5a975aa4c2a3db4",
      "9e323d0d45a346148a71f2e597a7437e",
      "43046efc6c8f4f9fafe06f337bb36640",
      "34c9920073ee40eb9acd456662b306f4",
      "306d8a765ebb43e7b6784db82ee96883",
      "2d7086f1c100435a8385ac45678cc951",
      "94a0fe0fb79843f098157788a0f9ccfb",
      "01c9791876b64339a3b056e602f8e1e7",
      "0ac6fac5bbc5484c9cb4ac7b007f1c32",
      "0dd304893e7b407eac35b48f5dc24836",
      "eb8dfaef30e64146a869fb5f5aa889dd",
      "37c013f5f27344d8ad740b672db2211f",
      "cbf1d9917e8642eea2a5a9280e6889f8",
      "f998046e990941e492cfa7e2029a2a9f",
      "69f0382e202b43d682193d06842677e6"
     ]
    },
    "id": "PY50XAAD-KcB",
    "outputId": "c7a61642-4a09-48fb-feb8-f857f231bb41"
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d37d7201fc334f7ba2676f1f59dd4ad8",
       "version_minor": 0,
       "version_major": 2
      },
      "text/plain": [
       "  0%|          | 0.00/5.95G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "306d8a765ebb43e7b6784db82ee96883",
       "version_minor": 0,
       "version_major": 2
      },
      "text/plain": [
       "  0%|          | 0.00/331M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pdb\n",
    "import torchaudio\n",
    "from torchaudio.datasets import LIBRISPEECH\n",
    "\n",
    "#Content data is a local folder for the node, this will accelerate the training process, but requires that you download the dataset every time you run the notebook\n",
    "data_path = './data'\n",
    "#If you need persistence, and want to avoid future downloads, you can set a path in google drive. However, be aware that this will make the training process slower\n",
    "\n",
    "if not os.path.isdir(data_path):\n",
    "    os.makedirs(data_path)\n",
    "\n",
    "trainDataset = LIBRISPEECH(data_path, url=\"train-clean-100\", download=True)\n",
    "testDataset = LIBRISPEECH(data_path, url=\"test-clean\", download=True)\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dfhEf9xhUOwt"
   },
   "source": [
    "# LAB SESSION 7\n",
    "---\n",
    "\n",
    "# Deep Learning for ASR\n",
    "\n",
    "### Audio Processing, Video Processing and Computer Vision\n",
    "\n",
    "### Bachelor in Data Science and Engineering\n",
    "### Academic Course 2021/2022\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KgYlPxNICRDq"
   },
   "source": [
    "1. INTRODUCTION AND OBJECTIVES\n",
    "2. UTILITY FUNCTIONS\n",
    "3. THE DATASET\n",
    "4. EVALUATING A SPEECH RECOGNITION MODEL\n",
    "5. THE SPEECH RECOGNITION MODEL\n",
    "6. THE TRAINING AND TESTING CODE\n",
    "\n",
    "\n",
    "NOTE: you will find sections in this notebook called exercises, which are the ones you are expected to report for evaluation. You will also find questions as comments in the code. Those are for you to think about, but we don't expect those to be handed over to us."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QFHaKO4l1Q3G"
   },
   "source": [
    "---\n",
    "## 1. INTRODUCTION AND OBJECTIVES\n",
    "---\n",
    "In this lab session, we are going to work with a deep network that performs automatic speech recognition using pytorch. This is, you give the model an audio file containing the voice of a person speaking english, and as the model \n",
    "will output a text string containing (hopefully) the words said by that person.\n",
    "\n",
    "To train such network with need voice audio files along with the text the model is expected to generate, hence, (voice, utterance) pairs. The [LibriSpeech](http://www.openslr.org/12/) dataset contains exactly that kind of data.\n",
    "\n",
    "The general architecture of the system is inspired on DeepSpeech 2 (by Baidu), and shown in the next illustration\n",
    "\n",
    "![Intro](https://landen.imgix.net/blog_KKMFzSYvUskeYQpX/assets/BHOBfDVTcGCQKTtp.png)\n",
    "\n",
    "Before diving into the code, here is a general overview of the complete system:\n",
    "\n",
    "\n",
    "1.   The audio is loaded and transformed into a spectrogram (we just changed from audio input to image input).\n",
    "2.   The spectrogram is passed through a CNN that computes visual features for different time-instants. At this point, a time instant is a bunch of columns from the spectrogram image.\n",
    "3.   The visual features are passed through a linear layer to accomodate the data dimensionality.\n",
    "4.   The processed visual features of each audio segment (time-instant) are used as a sequence in a recurrent neural network (RNN)\n",
    "5.   A final linear layer + softmax estimates, for each visual feature, the probability of being each possible letter. For that end, a CTC module and loss are employed to generate and align output sequences and labels. \n",
    "6.   Finally, the decoder generates the final text output.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tzEp5pZq1Q3T"
   },
   "source": [
    "---\n",
    "## 2. UTILITY FUNCTIONS\n",
    "---\n",
    "\n",
    "We need to execute now some utility functions that the rest of the code uses. In this session, there is only this TextTransform class. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "15wmecSLESvQ",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class TextTransform:\n",
    "    \"\"\"Maps characters to integers and vice versa\"\"\"\n",
    "    def __init__(self):\n",
    "        char_map_str = \"\"\"\n",
    "        ' 0\n",
    "        <SPACE> 1\n",
    "        a 2\n",
    "        b 3\n",
    "        c 4\n",
    "        d 5\n",
    "        e 6\n",
    "        f 7\n",
    "        g 8\n",
    "        h 9\n",
    "        i 10\n",
    "        j 11\n",
    "        k 12\n",
    "        l 13\n",
    "        m 14\n",
    "        n 15\n",
    "        o 16\n",
    "        p 17\n",
    "        q 18\n",
    "        r 19\n",
    "        s 20\n",
    "        t 21\n",
    "        u 22\n",
    "        v 23\n",
    "        w 24\n",
    "        x 25\n",
    "        y 26\n",
    "        z 27\n",
    "        \"\"\"\n",
    "        self.char_map = {}\n",
    "        self.index_map = {}\n",
    "        for line in char_map_str.strip().split('\\n'):\n",
    "            ch, index = line.split()\n",
    "            self.char_map[ch] = int(index)\n",
    "            self.index_map[int(index)] = ch\n",
    "        self.index_map[1] = ' '\n",
    "\n",
    "    def text_to_int(self, text):\n",
    "        \"\"\" Use a character map and convert text to an integer sequence \"\"\"\n",
    "        int_sequence = []\n",
    "        for c in text:\n",
    "            if c == ' ':\n",
    "                ch = self.char_map['<SPACE>']\n",
    "            else:\n",
    "                ch = self.char_map[c]\n",
    "            int_sequence.append(ch)\n",
    "        return int_sequence\n",
    "\n",
    "    def int_to_text(self, labels):\n",
    "        \"\"\" Use a character map and convert integer labels to a text sequence \"\"\"\n",
    "        string = []\n",
    "        for i in labels:\n",
    "            string.append(self.index_map[i])\n",
    "        return ''.join(string).replace('<SPACE>', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7UIwHx-FVdfE",
    "outputId": "7ab6550a-b228-44ed-8f5f-f156b354305e"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Text: \n",
      "\n",
      "Is encoded as:\n",
      "[] \n",
      "\n",
      "Text: \n",
      "A A\n",
      "Is encoded as:\n",
      "[2, 1, 2] \n",
      "\n",
      "Text: \n",
      "HELLO WORLD\n",
      "Is encoded as:\n",
      "[9, 6, 13, 13, 16, 1, 24, 16, 19, 13, 5] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "text_transform = TextTransform()\n",
    "texts = ['','A A','HELLO WORLD']\n",
    "\n",
    "for t in texts:\n",
    "    tti = text_transform.text_to_int(t.lower())\n",
    "    print(f'Text: \\n{t}')\n",
    "    print(\"Is encoded as:\")\n",
    "    print(tti, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_gIzino29Mjk"
   },
   "source": [
    "---\n",
    "## 3. THE DATASET\n",
    "---\n",
    "\n",
    "In pytorch, we use the [Dataset](https://pytorch.org/tutorials/beginner/data_loading_tutorial.html) class to read samples from disk and prepare them to be inputs of the model.\n",
    "\n",
    "Read the code and try to understand the different methods. Then, awnser the proposed questions in EXERCISE 1 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import numpy.random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import torchaudio\n",
    "\n",
    "from pydub import AudioSegment\n",
    "from pydub.playback import play\n",
    "from torchaudio.datasets import LIBRISPEECH"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "04wgJnIJFyZz"
   },
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "class LibriSpeech(LIBRISPEECH):\n",
    "    \n",
    "    \"\"\"\n",
    "    A dataset class derived from the torchaudio.datasets.LIBRISPEECH class.\n",
    "    The intention is to zip in this class all code related to loading the\n",
    "    training and test input samples for the model.\n",
    "    \n",
    "    Each sample in the dataset has 6 entries:\n",
    "        waveform, sample_rate, utterance, speaker_id, chapter_id, utterance_id\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, path, mode, n_feats, download=True, num_data=None):\n",
    "        \n",
    "        url = \"train-clean-100\" if mode == 'train' else \"test-clean\"\n",
    "        super(LibriSpeech, self).__init__( path, url=url, download=download)\n",
    "        \n",
    "        if not os.path.isdir(path):\n",
    "            os.makedirs(path)\n",
    "        \n",
    "        if mode == \"train\":\n",
    "            self.audioTransforms = nn.Sequential(\n",
    "                torchaudio.transforms.MelSpectrogram(sample_rate=16000, n_mels=n_feats),\n",
    "                torchaudio.transforms.FrequencyMasking(freq_mask_param=30),\n",
    "                torchaudio.transforms.TimeMasking(time_mask_param=100)\n",
    "            )\n",
    "        elif mode == \"test\":\n",
    "            self.audioTransforms = nn.Sequential(\n",
    "                torchaudio.transforms.MelSpectrogram(sample_rate=16000, n_mels=n_feats)\n",
    "            )\n",
    "        else:\n",
    "            raise RuntimeError(\"Unsupported mode: must be train or test\")\n",
    "                      \n",
    "        if num_data:\n",
    "          self.num_data = num_data\n",
    "          self.idx = np.random.choice(LIBRISPEECH.__len__(self), size=num_data,replace=True)\n",
    "        else:\n",
    "          self.num_data = LIBRISPEECH.__len__(self)\n",
    "          self.idx = np.arange(self.num_data)\n",
    "\n",
    "        self.text_transform = TextTransform()\n",
    "    \n",
    "    def __len__(self):\n",
    "      return self.num_data\n",
    "\n",
    "    def __getitem__(self, n, return_raw=False):\n",
    "        \n",
    "        \"\"\"\n",
    "        This function is called to retrieve each dataset sample. First, it\n",
    "        recovers the raw sample from the original torchaudio LIBRISPEECH \n",
    "        dataset (origSample), that contains the waveform and utterance transcript \n",
    "        \n",
    "            origSample = (tensor[1,numSamples], str)\n",
    "            \n",
    "            then, it applies the audio transformations defined on this class \n",
    "        constructor (that turns the [1,numSamples] audio signal into a [M,N] \n",
    "        spectrogram image) and encode the string utterance into a list of integers.\n",
    "        \n",
    "            spec = tensor[T, mel_coeffs]\n",
    "            label = list[len(utterance)]\n",
    "\n",
    "            mel_coeffs is the number of MEL coefficients used to compute the \n",
    "        spectrogram (the frequency dimension) and T is the resulting length of\n",
    "        the spectrogram (the time dimension) (check MelSpectrogram to understand\n",
    "        the relation between the original audio duration and the resulting \n",
    "        spectrogram length)\n",
    "        \n",
    "        \"\"\"\n",
    "        origSample = LIBRISPEECH.__getitem__(self, self.idx[n])\n",
    "        (waveform, _, utterance, _, _, _) = origSample\n",
    "        \n",
    "        spec = self.audioTransforms(waveform).squeeze(0).transpose(0, 1)\n",
    "        label = torch.Tensor(self.text_transform.text_to_int(utterance.lower()))\n",
    "        \n",
    "        if not return_raw:\n",
    "            return spec, label\n",
    "        else:\n",
    "            return waveform, spec, utterance, label\n",
    "    \n",
    "    \n",
    "    def collate(self, data):\n",
    "    \n",
    "        \"\"\"\n",
    "        This function is used by the DataLoaders to build the data batches\n",
    "        that are inputs of the speech recognition model.\n",
    "        \n",
    "        It receives as input a list of N tuples (N = batch size). Each tuple is\n",
    "        generated by this class method __getitem__(), like this:\n",
    "            \n",
    "            data = [ (spec1,label1), (spec2,label2), ...]\n",
    "        \n",
    "        The function stacks all the spectrograms and labels accounting\n",
    "        for the different lengths by means of a zero padding scheme.\n",
    "        The output is:\n",
    "\n",
    "            spectrograms = [N, 1, mel_coeffs, maxT]\n",
    "            labels       = [N, maxCharacters]\n",
    "            inputLengths = half the original spec lengths before the padding\n",
    "            labelLengths = original label lengths before the padding\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        spectrograms = []\n",
    "        labels = []\n",
    "        specLengths = []\n",
    "        labelLengths = []\n",
    "        \n",
    "        for spec, label in data:\n",
    "            \n",
    "            spectrograms.append(spec)\n",
    "            labels.append(label)\n",
    "            \n",
    "            specLengths.append(spec.shape[0]//2)\n",
    "            labelLengths.append(len(label))\n",
    "    \n",
    "        spectrograms = nn.utils.rnn.pad_sequence(\n",
    "            spectrograms, batch_first=True\n",
    "        ).unsqueeze(1).transpose(2, 3)\n",
    "\n",
    "        labels = nn.utils.rnn.pad_sequence(labels, batch_first=True)\n",
    "    \n",
    "        return spectrograms, labels, specLengths, labelLengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "l3GkqobqVdfF",
    "outputId": "794d35a4-4cb8-4203-8e22-e1fdd890361e"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/torchaudio/functional/functional.py:595: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (128) may be set too high. Or, the value for `n_freqs` (201) may be set too low.\n",
      "  \"At least one mel filterbank has all zero values. \"\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Visualize sample 1\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     }
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "\n",
      "Original transcription and generated labels\n",
      "\n",
      "THAT HAD ITS SOURCE AWAY BACK IN THE WOODS OF THE OLD CUTHBERT PLACE IT WAS REPUTED TO BE AN INTRICATE HEADLONG BROOK IN ITS EARLIER COURSE THROUGH THOSE WOODS WITH DARK SECRETS OF POOL AND CASCADE BUT BY THE TIME IT REACHED LYNDE'S HOLLOW IT WAS A QUIET WELL CONDUCTED LITTLE STREAM\n",
      "THAT HAD ITS SOURCE AWAY BACK IN THE WOODS OF THE OLD CUTHBERT PLACE IT WAS REPUTED TO BE AN INTRICATE HEADLONG BROOK IN ITS EARLIER COURSE THROUGH THOSE WOODS WITH DARK SECRETS OF POOL AND CASCADE BUT BY THE TIME IT REACHED LYNDE'S HOLLOW IT WAS A QUIET WELL CONDUCTED LITTLE STREAM\n",
      "tensor([21.,  9.,  2., 21.,  1.,  9.,  2.,  5.,  1., 10., 21., 20.,  1., 20.,\n",
      "        16., 22., 19.,  4.,  6.,  1.,  2., 24.,  2., 26.,  1.,  3.,  2.,  4.,\n",
      "        12.,  1., 10., 15.,  1., 21.,  9.,  6.,  1., 24., 16., 16.,  5., 20.,\n",
      "         1., 16.,  7.,  1., 21.,  9.,  6.,  1., 16., 13.,  5.,  1.,  4., 22.,\n",
      "        21.,  9.,  3.,  6., 19., 21.,  1., 17., 13.,  2.,  4.,  6.,  1., 10.,\n",
      "        21.,  1., 24.,  2., 20.,  1., 19.,  6., 17., 22., 21.,  6.,  5.,  1.,\n",
      "        21., 16.,  1.,  3.,  6.,  1.,  2., 15.,  1., 10., 15., 21., 19., 10.,\n",
      "         4.,  2., 21.,  6.,  1.,  9.,  6.,  2.,  5., 13., 16., 15.,  8.,  1.,\n",
      "         3., 19., 16., 16., 12.,  1., 10., 15.,  1., 10., 21., 20.,  1.,  6.,\n",
      "         2., 19., 13., 10.,  6., 19.,  1.,  4., 16., 22., 19., 20.,  6.,  1.,\n",
      "        21.,  9., 19., 16., 22.,  8.,  9.,  1., 21.,  9., 16., 20.,  6.,  1.,\n",
      "        24., 16., 16.,  5., 20.,  1., 24., 10., 21.,  9.,  1.,  5.,  2., 19.,\n",
      "        12.,  1., 20.,  6.,  4., 19.,  6., 21., 20.,  1., 16.,  7.,  1., 17.,\n",
      "        16., 16., 13.,  1.,  2., 15.,  5.,  1.,  4.,  2., 20.,  4.,  2.,  5.,\n",
      "         6.,  1.,  3., 22., 21.,  1.,  3., 26.,  1., 21.,  9.,  6.,  1., 21.,\n",
      "        10., 14.,  6.,  1., 10., 21.,  1., 19.,  6.,  2.,  4.,  9.,  6.,  5.,\n",
      "         1., 13., 26., 15.,  5.,  6.,  0., 20.,  1.,  9., 16., 13., 13., 16.,\n",
      "        24.,  1., 10., 21.,  1., 24.,  2., 20.,  1.,  2.,  1., 18., 22., 10.,\n",
      "         6., 21.,  1., 24.,  6., 13., 13.,  1.,  4., 16., 15.,  5., 22.,  4.,\n",
      "        21.,  6.,  5.,  1., 13., 10., 21., 21., 13.,  6.,  1., 20., 21., 19.,\n",
      "         6.,  2., 14.])\n",
      "\n",
      "\n",
      "Build a batch of samples and check the dimensions\n",
      "spectroams shape\n",
      "torch.Size([2, 1, 128, 1276])\n",
      "labels shape\n",
      "torch.Size([2, 283])\n"
     ]
    }
   ],
   "source": [
    "path = \"./data\"\n",
    "mode = \"train\"\n",
    "n_feats = 128\n",
    "download = True\n",
    "\n",
    "trainDataset = LibriSpeech(path, mode, n_feats, download=download)\n",
    "\n",
    "# get a sample and plot the original audio and transcription with their\n",
    "# corresponding augmented spectrogram and labels transformations\n",
    "\n",
    "i = 1\n",
    "print(f\"Visualize sample {i}\")\n",
    "\n",
    "samplei = trainDataset.__getitem__(i, return_raw=True)\n",
    "(waveform, spec, utterance, label) = samplei\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(waveform.t().numpy())\n",
    "plt.xlim([0, waveform.shape[1]])\n",
    "plt.xlabel(\"audio samples\")\n",
    "plt.ylabel(\"normalized amplitude\")\n",
    "plt.title(f\"Dataset LibriSpeech sample[{i}] waveform\")\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.imshow(spec.T.log2().detach().numpy(), cmap='gray_r', aspect='auto')\n",
    "plt.xlabel(\"time (window samples)\")\n",
    "plt.ylabel(\"frequency\")\n",
    "plt.title(f\"Augmented Mel Spectrogram of sample[{i}]\")\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\\nOriginal transcription and generated labels\\n\")\n",
    "print(utterance)\n",
    "print(text_transform.int_to_text(label.tolist()).upper())\n",
    "print(label)\n",
    "\n",
    "# lets build a batch of two samples to check the dimensions of the network\n",
    "# inputs\n",
    "print(\"\\n\\nBuild a batch of samples and check the dimensions\")\n",
    "sample0, sample1 = trainDataset[0], trainDataset[1]\n",
    "data = (sample0, sample1)\n",
    "batch = trainDataset.collate(data)\n",
    "\n",
    "spectrograms, labels, specLengths, labelLengths = batch\n",
    "print(\"spectroams shape\")\n",
    "print(spectrograms.shape)\n",
    "print(\"labels shape\")\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dRdv4XQSw7uV"
   },
   "source": [
    "We next hear the speech of the two samples. The next cell only works in local mode and not in Google Colab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vMqGF9ZYw7uW"
   },
   "outputs": [],
   "source": [
    "#Function that plays a numpy array of samples\n",
    "def playSample(samples):\n",
    "    #Convert to 16bit-unsigned integer\n",
    "    samplesb = np.int16(samples * 2 ** 15)\n",
    "\n",
    "    audio_segment = AudioSegment(\n",
    "        samplesb.tobytes(), \n",
    "        frame_rate=16000,\n",
    "        sample_width=2, \n",
    "        channels=1\n",
    "    )\n",
    "    play(audio_segment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eXBlCNtIVdfH"
   },
   "outputs": [],
   "source": [
    "# #Play sample 0\n",
    "# playSample(trainDataset.__getitem__(0,return_raw=True)[0].numpy())\n",
    "# #Play sample 1\n",
    "# playSample(trainDataset.__getitem__(1,return_raw=True)[0].numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bvqTUT6NkRxr"
   },
   "source": [
    "---\n",
    "### [EXERCISE 1]\n",
    "---\n",
    "\n",
    "The LibriSpeech class is responsible of preparing the input data  for\n",
    "the speech recognition models. It must read the audio files with their\n",
    "corresponding transcriptions from disk, and apply all the necessary \n",
    "transformations (depending on whether the data is for train or test)\n",
    "\n",
    "In particular, note that this class computes spectrograms (which are two\n",
    "dimensional signals that usually are visualized as images).\n",
    "\n",
    "Asnwer the following questions in the cell above:\n",
    "\n",
    "1.   Are we losing any information from the original audio signals by\n",
    "      transforming them into MEL spectrograms and giving the model just that?\n",
    "      In other words, can you recover the original audio signal from the spectrogram alone?\n",
    "2.   If deep learning is about models learning what features to extract\n",
    "      from the raw data, why aren't we giving the network the raw\n",
    "      audio signals?\n",
    "3.   Can you explain the data augmentation mechanism implemented in this \n",
    "      class? (FrequencyMasking and TimeMasking functions), what would you listen by playing the augmented samples in comparison with the original ones?\n",
    "\n",
    "      HINT: Try to find information such as [this](https://arxiv.org/abs/1706.09559) analyzing the first two questions of this exercise.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I6R5Ratvw7uY"
   },
   "source": [
    "### EX 1 - QUESTION 1\n",
    "\n",
    "> When an audio signal is transformed by MFCC, the great detail of individual frames information is always lost in the process. Therefore, a lower-quality signal can be recovered, which is very similar to the original one, but not as precise. \n",
    "\n",
    ">Moreover, there exists a method that could optimize this reconstruction process by minimizing loss: the **Griffin-Lim Algorithm** is a phase reconstruction technique based on the short-time Fourier transform's redundancy. It promotes spectrogram consistency by iterating two projections (a spectrogram is said to be consistent when its inter-bin dependency is preserved due to STFT redundancy).\n",
    "\n",
    "> While this approach is often used for cases in which there is a modified STFT/spectrogram of some real signal, or one generated by a neural network, it might be useful in reconstructing the signal with less loss of information.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### EX 1 - QUESTION 2\n",
    "\n",
    "> Learning acoustic models directly from the raw waveform data is quite complex and, in our particular case, would be unproductive and lead to poor results. Given the relatively low number of layers that our neural networks have, we believe that they are insufficient for building high-level discriminative features. If we were to feed our model with raw signals we would encounter a ***high occurrence of noise***, giving rise to frequency bands that would only hinder and worsen our speech recognition model. \n",
    "\n",
    "> Using time-domain waveforms as inputs might be more reliable if we had CNNs with **dozens of weight layers**, being optimized over very long sequences, and the application was not for speech recognition, which is not the case."
   ],
   "metadata": {
    "id": "8ZgSZdzf8YOS"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### EX 1 - QUESTION 3\n",
    "\n",
    "> The first function iteratively applies a concealment or screening (masking) to the **frequency channels [f0, f0+f]** of the spectrogram. It randomly picks “f” and “f0” from two uniform distributions: for the first, 0 to frequency mask parameter F. For the second, 0 to (number of freq. channels - f). It is performed until it reaches the length of the mask.  When listening to these modified versions, the weaker sound will be inaudible, as the brain will only process the masking sound. This effect will be even more pronounced especially if the weaker sound has a frequency closer to the masking sound.\n",
    "\n",
    "\n",
    "> In the temporal masking function, a similar process is applied, but to the **time domain**: it obscures one sound by another, but in this case it occurs when the signal and the masker are not presented simultaneously. It iteratively masks t time steps [t0, t0+t].  It randomly picks “t” and “t0” from two uniform distributions: for the first, 0 to time mask parameter T. For the second, 0 to (number of time channels - t). When listening to these modified versions, the masking sound will make the masked sound inaudible. In this situation, the more intense tone tends to mask the weaker tone. Depending on the instant of time at which the masking stimulus occurs relative to the instant at which the masking occurs, a distinction should be able to be made: post-masking and pre-masking."
   ],
   "metadata": {
    "id": "RciHq77V8cGd"
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5x9OFxY8MqVX"
   },
   "source": [
    "---\n",
    "## 4. EVALUATING A SPEECH RECOGNITION MODEL\n",
    "---\n",
    "\n",
    "In image classification it is common to have a single integer label for each test image. Thus, metrics such as accuracy or confusion matrices are common for evaluating those systems. \n",
    "\n",
    "However, in a speech recognition problem we have two sentences with potentially different lengths:\n",
    "\n",
    "1.   The ground truth one:  containing the actual words that were spoken\n",
    "2.   The model prediction:  containing the transcription of our model outputs\n",
    "\n",
    "How do we measure how well the sentences produced by the model fit the ground truth?. Two common metrics are the Character and Word Error Rates (CER, WER). The formulas and explanations for computing them are in the next code cell as comments inside the functions. In the main section of the next cell there are also some examples to help you understand the metrics.\n",
    "\n",
    "Execute the cell, play with the samples and try to answer the questions in excersice 2.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SkPK55uAI1k6"
   },
   "outputs": [],
   "source": [
    "def _levenshtein_distance(ref, hyp):\n",
    "    \"\"\"Levenshtein distance is a string metric for measuring the difference\n",
    "    between two sequences. Informally, the levenshtein disctance is defined as\n",
    "    the minimum number of single-character edits (substitutions, insertions or\n",
    "    deletions) required to change one word into the other. We can naturally\n",
    "    extend the edits to word level when calculate levenshtein distance for\n",
    "    two sentences.\n",
    "    \"\"\"\n",
    "    m = len(ref)\n",
    "    n = len(hyp)\n",
    "\n",
    "    # special case\n",
    "    if ref == hyp:\n",
    "        return 0\n",
    "    if m == 0:\n",
    "        return n\n",
    "    if n == 0:\n",
    "        return m\n",
    "\n",
    "    if m < n:\n",
    "        ref, hyp = hyp, ref\n",
    "        m, n = n, m\n",
    "\n",
    "    # use O(min(m, n)) space\n",
    "    distance = np.zeros((2, n + 1), dtype=np.int32)\n",
    "\n",
    "    # initialize distance matrix\n",
    "    for j in range(0,n + 1):\n",
    "        distance[0][j] = j\n",
    "\n",
    "    # calculate levenshtein distance\n",
    "    for i in range(1, m + 1):\n",
    "        prev_row_idx = (i - 1) % 2\n",
    "        cur_row_idx = i % 2\n",
    "        distance[cur_row_idx][0] = i\n",
    "        for j in range(1, n + 1):\n",
    "            if ref[i - 1] == hyp[j - 1]:\n",
    "                distance[cur_row_idx][j] = distance[prev_row_idx][j - 1]\n",
    "            else:\n",
    "                s_num = distance[prev_row_idx][j - 1] + 1\n",
    "                i_num = distance[cur_row_idx][j - 1] + 1\n",
    "                d_num = distance[prev_row_idx][j] + 1\n",
    "                distance[cur_row_idx][j] = min(s_num, i_num, d_num)\n",
    "\n",
    "    return distance[m % 2][n]\n",
    "\n",
    "\n",
    "def word_errors(reference, hypothesis, ignore_case=False, delimiter=' '):\n",
    "    \"\"\"Compute the levenshtein distance between reference sequence and\n",
    "    hypothesis sequence in word-level.\n",
    "    :param reference: The reference sentence.\n",
    "    :type reference: basestring\n",
    "    :param hypothesis: The hypothesis sentence.\n",
    "    :type hypothesis: basestring\n",
    "    :param ignore_case: Whether case-sensitive or not.\n",
    "    :type ignore_case: bool\n",
    "    :param delimiter: Delimiter of input sentences.\n",
    "    :type delimiter: char\n",
    "    :return: Levenshtein distance and word number of reference sentence.\n",
    "    :rtype: list\n",
    "    \"\"\"\n",
    "    if ignore_case == True:\n",
    "        reference = reference.lower()\n",
    "        hypothesis = hypothesis.lower()\n",
    "\n",
    "    ref_words = reference.split(delimiter)\n",
    "    hyp_words = hypothesis.split(delimiter)\n",
    "    \n",
    "    edit_distance = _levenshtein_distance(ref_words, hyp_words)\n",
    "    return float(edit_distance), len(ref_words)\n",
    "\n",
    "\n",
    "def char_errors(reference, hypothesis, ignore_case=False, remove_space=False):\n",
    "    \"\"\"Compute the levenshtein distance between reference sequence and\n",
    "    hypothesis sequence in char-level.\n",
    "    :param reference: The reference sentence.\n",
    "    :type reference: basestring\n",
    "    :param hypothesis: The hypothesis sentence.\n",
    "    :type hypothesis: basestring\n",
    "    :param ignore_case: Whether case-sensitive or not.\n",
    "    :type ignore_case: bool\n",
    "    :param remove_space: Whether remove internal space characters\n",
    "    :type remove_space: bool\n",
    "    :return: Levenshtein distance and length of reference sentence.\n",
    "    :rtype: list\n",
    "    \"\"\"\n",
    "    if ignore_case == True:\n",
    "        reference = reference.lower()\n",
    "        hypothesis = hypothesis.lower()\n",
    "\n",
    "    join_char = ' '\n",
    "    if remove_space == True:\n",
    "        join_char = ''\n",
    "\n",
    "    reference = join_char.join(filter(None, reference.split(' ')))\n",
    "    hypothesis = join_char.join(filter(None, hypothesis.split(' ')))\n",
    "    \n",
    "    edit_distance = _levenshtein_distance(reference, hypothesis)\n",
    "    return float(edit_distance), len(reference)\n",
    "\n",
    "\n",
    "def wer(reference, hypothesis, ignore_case=False, delimiter=' '):\n",
    "    \"\"\"Calculate word error rate (WER). WER compares reference text and\n",
    "    hypothesis text in word-level. WER is defined as:\n",
    "    .. math::\n",
    "        WER = (Sw + Dw + Iw) / Nw\n",
    "    where\n",
    "    .. code-block:: text\n",
    "        Sw is the number of words substituted,\n",
    "        Dw is the number of words deleted,\n",
    "        Iw is the number of words inserted,\n",
    "        Nw is the number of words in the reference\n",
    "    We can use levenshtein distance to calculate WER. Please draw an attention\n",
    "    that empty items will be removed when splitting sentences by delimiter.\n",
    "    :param reference: The reference sentence.\n",
    "    :type reference: basestring\n",
    "    :param hypothesis: The hypothesis sentence.\n",
    "    :type hypothesis: basestring\n",
    "    :param ignore_case: Whether case-sensitive or not.\n",
    "    :type ignore_case: bool\n",
    "    :param delimiter: Delimiter of input sentences.\n",
    "    :type delimiter: char\n",
    "    :return: Word error rate.\n",
    "    :rtype: float\n",
    "    :raises ValueError: If word number of reference is zero.\n",
    "    \"\"\"\n",
    "    edit_distance, ref_len = word_errors(reference, hypothesis, ignore_case, delimiter)\n",
    "\n",
    "    if ref_len == 0:\n",
    "        raise ValueError(\"Reference's word number should be greater than 0.\")\n",
    "\n",
    "    wer = float(edit_distance) / ref_len\n",
    "    return wer\n",
    "\n",
    "\n",
    "def cer(reference, hypothesis, ignore_case=False, remove_space=False):\n",
    "    \"\"\"Calculate charactor error rate (CER). CER compares reference text and\n",
    "    hypothesis text in char-level. CER is defined as:\n",
    "    .. math::\n",
    "        CER = (Sc + Dc + Ic) / Nc\n",
    "    where\n",
    "    .. code-block:: text\n",
    "        Sc is the number of characters substituted,\n",
    "        Dc is the number of characters deleted,\n",
    "        Ic is the number of characters inserted\n",
    "        Nc is the number of characters in the reference\n",
    "    We can use levenshtein distance to calculate CER. Chinese input should be\n",
    "    encoded to unicode. Please draw an attention that the leading and tailing\n",
    "    space characters will be truncated and multiple consecutive space\n",
    "    characters in a sentence will be replaced by one space character.\n",
    "    :param reference: The reference sentence.\n",
    "    :type reference: basestring\n",
    "    :param hypothesis: The hypothesis sentence.\n",
    "    :type hypothesis: basestring\n",
    "    :param ignore_case: Whether case-sensitive or not.\n",
    "    :type ignore_case: bool\n",
    "    :param remove_space: Whether remove internal space characters\n",
    "    :type remove_space: bool\n",
    "    :return: Character error rate.\n",
    "    :rtype: float\n",
    "    :raises ValueError: If the reference length is zero.\n",
    "    \"\"\"\n",
    "    edit_distance, ref_len = char_errors(reference, hypothesis, ignore_case, remove_space)\n",
    "\n",
    "    if ref_len == 0:\n",
    "        raise ValueError(\"Length of reference should be greater than 0.\")\n",
    "\n",
    "    cer = float(edit_distance) / ref_len\n",
    "    return cer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aaoAayRGVdfI",
    "outputId": "7c75d803-b15b-4c2c-fbd2-a7bf76d961c5"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Real text (ground truth labels)): HELLO\n",
      "Predicted text (Model output)): HELLO\n",
      "CER rate: 0.00\n",
      "WER rate: 0.00\n",
      "\n",
      "Real text (ground truth labels)): HELLO\n",
      "Predicted text (Model output)): HELLA\n",
      "CER rate: 0.20\n",
      "WER rate: 1.00\n",
      "\n",
      "Real text (ground truth labels)): HELLO WORLD\n",
      "Predicted text (Model output)): HELLO WORLL\n",
      "CER rate: 0.09\n",
      "WER rate: 0.50\n",
      "\n",
      "Real text (ground truth labels)): SUP\n",
      "Predicted text (Model output)): YOUR MODEL OUTPUTS TOO MANY WORDS\n",
      "CER rate: 10.33\n",
      "WER rate: 6.00\n",
      "\n"
     ]
    }
   ],
   "source": [
    "refs = ['HELLO', 'HELLO', 'HELLO WORLD', 'SUP']\n",
    "hyps = ['HELLO', 'HELLA', 'HELLO WORLL', 'YOUR MODEL OUTPUTS TOO MANY WORDS']\n",
    "\n",
    "for ref, hyp in zip(refs, hyps):\n",
    "    print(f'Real text (ground truth labels)): {ref}')\n",
    "    print(f'Predicted text (Model output)): {hyp}')\n",
    "    print(f'CER rate: {cer(ref, hyp):.2f}')\n",
    "    print(f'WER rate: {wer(ref, hyp):.2f}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KOw4VFffVdfJ"
   },
   "source": [
    "### [EXERCISE 2]\n",
    "\n",
    "- Describe how CER and WER are computed based on the results of the examples executed below (you can use any other illustrative example that you find appropriate).\n",
    "\n",
    "- In your opinion, which metric is more suitable to assess the capability of the ASR system? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iOYYF37-VdfJ"
   },
   "source": [
    "### EX 2 - QUESTION 1\n",
    "\n",
    "> To measure the accuracy with CER and WER, instead of evaluating the output indicating 1 for a complete match or 0 for no match, we break these matches down to the word and character level. In this way, we use these error rates to determine the precise extent, on whatever scale we want, to which the prediction and GT differ from each other. It is not simply counting how many words or characters are misspelled, but the possibility of overshooting or undershooting comes into play. For this, as explained in the theory, we use the Levenshtein distance, which allows us to know the minimum number of edits (words or characters, for WER or CER respectively) that are required to change one structure (again, respectively sentence or word) into another. These edits can be **substitution, deletion or insertion** errors.\n",
    "\n",
    "> For example, calculating the CER for **'HELLO’ (gt) vs 'HELLA’**, we have 1 substitution, 0 deletions and 0 insertions, being 5 the number of characters of the GT (and in this case of the predicted output too), so the CER = (1+0+0)/5 = 0.2\n",
    "\n",
    "> Calculating the WER for **'SUP' (gt) vs 'YOUR MODEL OUTPUTS TOO MANY WORDS'**, we have that the number of words of the ground truth is 1, but in the predicted output we would have 1 misspelling (SUP vs YOUR) and 5 insertions, so WER = (1 + 0 + 5)/1 = 6.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### EX 2 - QUESTION 2\n",
    "\n",
    "> We have conducted some research, and we believe that the industry standard is using the Word Error Rate (WER) as evaluation metric, so a lower word error rate shows superior accuracy in recognition of speech. However, we have found that in a Microsoft Research experiment, it was shown that, if people were trained under \"that matches the optimization objective for understanding\", (Wang, Acero and Chelba, 2003) they would show a higher accuracy in understanding of language than other people who showed a lower word error rate. Evidently these are different situations, deep learning models vs. human performance, but since the ultimate goal of these algorithms is to match their recognition capability to ours, perhaps it is not unreasonable to think that the true understanding of spoken language relates to more than just highly accurate word recognition. \n",
    "\n",
    "> For us it makes more sense to use the CER, since the characters are always of invariable size (1), while the size of the words varies enormously. In addition, a word is incorrectly recognized if just one letter in it is not correct, so it does not seem to us to be a very “fair” or consistent criterion."
   ],
   "metadata": {
    "id": "3yq83SsfXLwk"
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uPUExldKNcQc"
   },
   "source": [
    "---\n",
    "## 4. THE SPEECH RECOGNITION MODEL\n",
    "---\n",
    "\n",
    "The next code cell contains the speech recognition model class: SpeechRecognitionModel. The following code does not exactly implement the model depicted in the figure in section 1 but a simplified version with a vainilla RNN. \n",
    "\n",
    "Take a look at the main at the end of the code cell and answer the questions in excercise 3.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jYpQc_Z6NkQM"
   },
   "outputs": [],
   "source": [
    "class CNNLayerNorm(nn.Module):\n",
    "    \"\"\"\n",
    "    This class is a convenience to do the transposition of the tensor, since\n",
    "    we want to normalize the features and not the time dimensions.\n",
    "    \n",
    "    This is similar to a batchnorm layer but you apply it before the conv layers\n",
    "    not after (pretty much the same idea with minor modifications). \n",
    "    \"\"\"\n",
    "    def __init__(self, n_feats):\n",
    "        super(CNNLayerNorm, self).__init__()\n",
    "        self.layer_norm = nn.LayerNorm(n_feats)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x (batch, channel, feature, time)\n",
    "        x = x.transpose(2, 3).contiguous() # (batch, channel, time, feature)\n",
    "        x = self.layer_norm(x)\n",
    "        return x.transpose(2, 3).contiguous() # (batch, channel, feature, time) \n",
    "\n",
    "\n",
    "class ResidualCNN(nn.Module):\n",
    "    \"\"\"\n",
    "    This is basically a block of convolutional residual network. Since the\n",
    "    input and output has the same dimensions (as long as the stride=1)\n",
    "    you can stack as many as you want.\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, out_channels, kernel, stride, dropout, n_feats):\n",
    "        super(ResidualCNN, self).__init__()\n",
    "\n",
    "        self.cnn1 = nn.Conv2d(in_channels, out_channels, kernel, stride, padding=kernel//2)\n",
    "        self.cnn2 = nn.Conv2d(out_channels, out_channels, kernel, stride, padding=kernel//2)\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "        self.layer_norm1 = CNNLayerNorm(n_feats)\n",
    "        self.layer_norm2 = CNNLayerNorm(n_feats)\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x  # (batch, channel, feature, time)\n",
    "        x = self.layer_norm1(x)\n",
    "        x = F.gelu(x)   \n",
    "        x = self.dropout1(x)\n",
    "        x = self.cnn1(x)\n",
    "        x = self.layer_norm2(x)\n",
    "        x = F.gelu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.cnn2(x)\n",
    "        x += residual\n",
    "        return x # (batch, channel, feature, time)\n",
    "    \n",
    "class SimpleRNN(nn.Module):\n",
    "\n",
    "    def __init__(self, rnn_dim, hidden_size, dropout, batch_first):\n",
    "        super(SimpleRNN, self).__init__()\n",
    "\n",
    "        self.RNN = nn.RNN(\n",
    "            input_size=rnn_dim, hidden_size=hidden_size,\n",
    "            num_layers=1, batch_first=batch_first)\n",
    "        \n",
    "        self.layer_norm = nn.LayerNorm(rnn_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer_norm(x)\n",
    "        x = F.gelu(x)\n",
    "        x, _ = self.RNN(x)\n",
    "        x = self.dropout(x)\n",
    "        return x\n",
    "    \n",
    "class SimpleGRU(nn.Module):\n",
    "    \n",
    "    def __init__(self, rnn_dim, hidden_size, dropout, batch_first, bidirectional=False):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.GRU = nn.GRU(\n",
    "            input_size=rnn_dim,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=1,\n",
    "            batch_first=batch_first,\n",
    "            bidirectional=bidirectional\n",
    "        )\n",
    "        self.layer_norm = nn.LayerNorm(rnn_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.layer_norm(x)\n",
    "        x = F.gelu(x)\n",
    "        x, _ = self.GRU(x)\n",
    "        x = self.dropout(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "77y0XJxMVdfK"
   },
   "outputs": [],
   "source": [
    "class SpeechRecognitionModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_cnn_layers, n_rnn_layers, rnn_dim, n_class, n_feats,\n",
    "                 stride=2, dropout=0.1, use_GRU=False, bidirectionalRNN=False):\n",
    "        \n",
    "        super(SpeechRecognitionModel, self).__init__()\n",
    "        \n",
    "        n_feats = n_feats // stride\n",
    "        self.cnn = nn.Conv2d(1, 32, 3, stride=stride, padding=3//2)  # cnn for extracting heirachal features\n",
    "\n",
    "        # n residual cnn layers with filter size of 32\n",
    "        self.rescnn_layers = nn.Sequential(*[\n",
    "            ResidualCNN(32, 32, kernel=3, stride=1, dropout=dropout, n_feats=n_feats) \n",
    "            for _ in range(n_cnn_layers)\n",
    "        ])\n",
    "        #Linear\n",
    "        self.fully_connected = nn.Linear(n_feats*32, rnn_dim)\n",
    "\n",
    "        #RNN\n",
    "        if use_GRU:\n",
    "            self.recursive_layers = nn.Sequential(*[\n",
    "                SimpleGRU(\n",
    "                    rnn_dim=rnn_dim if (i==0 or not bidirectionalRNN) else 2*rnn_dim,\n",
    "                    hidden_size=rnn_dim,\n",
    "                    dropout=dropout,\n",
    "                    batch_first=i==0,\n",
    "                    bidirectional=bidirectionalRNN\n",
    "                )\n",
    "              for i in range(n_rnn_layers)\n",
    "            ])\n",
    "        else:\n",
    "            self.recursive_layers = nn.Sequential(*[\n",
    "                SimpleRNN(\n",
    "                    rnn_dim=rnn_dim,\n",
    "                    hidden_size=rnn_dim,\n",
    "                    dropout=dropout,\n",
    "                    batch_first=i==0\n",
    "                )\n",
    "              for i in range(n_rnn_layers)\n",
    "            ])\n",
    "        if bidirectionalRNN:\n",
    "            output_channels = 2 * rnn_dim\n",
    "        else:\n",
    "            output_channels = rnn_dim\n",
    "        #Final Classifier with stack of linear layers\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(output_channels, rnn_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(rnn_dim, n_class)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.cnn(x)\n",
    "        x = self.rescnn_layers(x)\n",
    "        sizes = x.size()\n",
    "        x = x.view(sizes[0], sizes[1] * sizes[2], sizes[3])  # (batch, feature, time)\n",
    "        x = x.transpose(1, 2) # (batch, time, feature)\n",
    "        x = self.fully_connected(x)\n",
    "        x = self.recursive_layers(x)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "def get_sr_model(model, model_params, device='cpu'):\n",
    "    return model(\n",
    "        model_params['n_cnn_layers'], model_params['n_rnn_layers'],\n",
    "        model_params['rnn_dim'], model_params['n_class'], model_params['n_feats'],\n",
    "        model_params['stride'], model_params['dropout'],\n",
    "        model_params['use_gru'], model_params['bidirectional']\n",
    "    ).to(device)"
   ],
   "metadata": {
    "id": "CKVETMAc1y5z"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5WO6Wy-RVdfK",
    "outputId": "19d3a56c-1c32-4efe-a34b-cb4ee5bcd6d4"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "entra\n",
      "torch.Size([1, 625, 29])\n"
     ]
    }
   ],
   "source": [
    "print('entra')\n",
    "\n",
    "# these are the options of the model\n",
    "hparams = {\n",
    "    \"n_cnn_layers\": 1,\n",
    "    \"n_rnn_layers\": 2,\n",
    "    \"rnn_dim\": 256,\n",
    "    \"n_class\": 29,\n",
    "    \"n_feats\": 128, # number of mel coeffs in the spectrogram\n",
    "    \"stride\":2,\n",
    "    \"dropout\": 0.1,\n",
    "    \"use_gru\": True,\n",
    "    \"bidirectional\": True,\n",
    "}\n",
    "\n",
    "model = get_sr_model(SpeechRecognitionModel, hparams)\n",
    "\n",
    "# Lets go over each step in the forward method of the SpeechRecognitionModel\n",
    "# to understand the inputs and outputs of each submodule inside it\n",
    "\n",
    "# generate a batch with a single image to use as model input (just noise\n",
    "# with the proper dimensions)\n",
    "x = torch.randn(1, 1, 128, 1249)\n",
    "\n",
    "# the model first uses a 32 filter conv layer with a stride of 2 which halves\n",
    "# the time and frequency dimensions of the input spectrogram\n",
    "x = model.cnn(x) # x.shape = [1, 32, 64, 625]\n",
    "\n",
    "# then it goes through the residual backbone preserving its shape\n",
    "x = model.rescnn_layers(x) # x.shape = [1, 32, 64, 625]\n",
    "\n",
    "# now the x volume its reshaped to join all features\n",
    "sizes = x.size()\n",
    "x = x.view(sizes[0], sizes[1] * sizes[2], sizes[3])  # (batch, feature, time)\n",
    "x = x.transpose(1, 2) # (batch, time, feature) with x.shape = [1, 625, 2048]\n",
    "\n",
    "# at this point we have 625 time instants, each represented by a 2048 feature vector\n",
    "# we compress the 2048 feature vectors into 512 ones using a fully connected\n",
    "x = model.fully_connected(x) # x.shape = [1, 625, 512] (numImage,timeInstant,Feature)\n",
    "\n",
    "# now, we use the recurrent layer that will give us for each of the 625\n",
    "# time instants, a feature vector of dimension 512 \n",
    "x = model.recursive_layers(x) # x.shape = [1, 625, 512]\n",
    "\n",
    "# finally, we need a classifier to take every of the 625 feature vectors (of\n",
    "# dimensionality 512) coming out of the rnn and give a distribution of \n",
    "# scores over each possible letter\n",
    "x = model.classifier(x) # x.shape = [1, 625, 29]\n",
    "\n",
    "# to get the final text out of x, you need to implement some strategy\n",
    "# such as the one in the greedyDecoder function provided.\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s4x0XsvUPkH_"
   },
   "source": [
    "---\n",
    "### [EXERCISE 3]\n",
    "---\n",
    "\n",
    "In the previous cell, define a new class `SimpleGRU` and integrate it into the SpeechRecognitionModel class, by filling the blank spaces where code is required.\n",
    "\n",
    "This class should be inspired in the SimpleRNN class, but substituting the vainilla RNN by a GRU layer with the possibility of being bidirectional. The constructor method should have the following interface:\n",
    "\n",
    "`__init__(self, rnn_dim, hidden_size, dropout, batch_first,bidirectional=False)`\n",
    "\n",
    "In addition, in order to get a class compatible with the pretrained weights provided in the practice, the object implementing the GRU layer should be called: `self.GRU`\n",
    "\n",
    "HINT for integration: Bidirectional recursive layers are internally implemented in pytorch as two\n",
    "    individual layers (but sharing weights), each of them looking at the input data in reverse order\n",
    "    from each other. Both individual outputs are then concatenated into a \n",
    "    final tensor. Thus, the dimension of the output gets doubled with \n",
    "    respect to a non bidirectional GRU. This will cause the first fc layer in \n",
    "    the classifier to fail if not taken into account. Change the fc layer that receives the RNN \n",
    "    output to expect rnn_dim*2 as input dimension when using \n",
    "    bidirectional=True option.\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hpvzOzYkR0Sm"
   },
   "source": [
    "---\n",
    "## 4. TRAINING AND TESTING THE ASR MODEL\n",
    "---\n",
    "\n",
    "The next code cell contains all the necessary to train and test the speech recognition model. Check that we are using the CTC loss to train our network.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bd9yvM_QSRQc",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "text_transform = TextTransform()\n",
    "\n",
    "def GreedyDecoder(output, labels, label_lengths, blank_label=28, collapse_repeated=True):\n",
    "    arg_maxes = torch.argmax(output, dim=2)\n",
    "    decodes = []\n",
    "    targets = []\n",
    "    for i, args in enumerate(arg_maxes):\n",
    "        decode = []\n",
    "        targets.append(text_transform.int_to_text(labels[i][:label_lengths[i]].tolist()))\n",
    "        for j, index in enumerate(args):\n",
    "            if index != blank_label:\n",
    "                if collapse_repeated and j != 0 and index == args[j-1]:\n",
    "                    continue\n",
    "                decode.append(index.item())\n",
    "        decodes.append(text_transform.int_to_text(decode))\n",
    "    return decodes, targets\n",
    "\n",
    "\n",
    "class IterMeter(object):\n",
    "    \"\"\"keeps track of total iterations\"\"\"\n",
    "    def __init__(self):\n",
    "        self.val = 0\n",
    "\n",
    "    def step(self):\n",
    "        self.val += 1\n",
    "\n",
    "    def get(self):\n",
    "        return self.val\n",
    "\n",
    "\n",
    "def train(model, device, train_loader, criterion, optimizer, scheduler, epoch, iter_meter):\n",
    "    model.train()\n",
    "    data_len = len(train_loader.dataset)\n",
    "    print(f'Train Epoch: {epoch} lr = {scheduler.get_lr()[0]}')\n",
    "\n",
    "    for batch_idx, _data in enumerate(train_loader):\n",
    "        spectrograms, labels, input_lengths, label_lengths = _data \n",
    "        spectrograms, labels = spectrograms.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output = model(spectrograms)  # (batch, time, n_class)\n",
    "        output = F.log_softmax(output, dim=2)\n",
    "        output = output.transpose(0, 1) # (time, batch, n_class)\n",
    "        loss = criterion(output, labels, input_lengths, label_lengths)\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        iter_meter.step()\n",
    "        if batch_idx % 100 == 0 or batch_idx == data_len:\n",
    "            print('Train Epoch: {} [{:04}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(spectrograms), data_len,\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "            \n",
    "\n",
    "def test(model, device, test_loader, criterion):\n",
    "    print('\\nEvaluating...')\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    test_cer, test_wer = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, _data in enumerate(test_loader):\n",
    "            spectrograms, labels, input_lengths, label_lengths = _data \n",
    "            spectrograms, labels = spectrograms.to(device), labels.to(device)\n",
    "\n",
    "            output = model(spectrograms)  # (batch, time, n_class)\n",
    "            output = F.log_softmax(output, dim=2)\n",
    "            output = output.transpose(0, 1) # (time, batch, n_class)\n",
    "            \n",
    "            loss = criterion(output, labels, input_lengths, label_lengths)\n",
    "            test_loss += loss.item() / len(test_loader)\n",
    "\n",
    "            decoded_preds, decoded_targets = GreedyDecoder(output.transpose(0, 1), labels, label_lengths)\n",
    "            for j in range(len(decoded_preds)):\n",
    "                test_cer.append(cer(decoded_targets[j], decoded_preds[j]))\n",
    "                test_wer.append(wer(decoded_targets[j], decoded_preds[j]))\n",
    "\n",
    "    avg_cer = sum(test_cer)/len(test_cer)\n",
    "    avg_wer = sum(test_wer)/len(test_wer)\n",
    "\n",
    "    print(f'\\nTest set: Average loss: {test_loss:.4f}, Average CER: {avg_cer:4f} Average WER: {avg_wer:.4f}\\n')\n",
    "    print('\\nEXAMPLE')\n",
    "    print('GT:')\n",
    "    print(decoded_targets[-1])\n",
    "    print(\"\\nNetwork output:\")\n",
    "    print(decoded_preds[-1])\n",
    "\n",
    "    return list(zip(decoded_targets, decoded_preds, test_cer, test_wer)), (avg_cer, avg_wer, test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZYNF8vBoVdfL"
   },
   "outputs": [],
   "source": [
    "def get_dataloader(dataset, batch_size, use_cuda, num_workers, shuffle=True):\n",
    "    kwargs = {'num_workers': num_workers, 'pin_memory': True} if use_cuda else {}\n",
    "    return data.DataLoader(\n",
    "        dataset=dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        collate_fn=dataset.collate,\n",
    "        **kwargs\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "def trainloop(model_params, training_params, device, use_cuda, num_workers=2):\n",
    "\n",
    "    # Subsample the training dataset and limit the number of utterances to 10000 (,num_data=10000)\n",
    "    train_dataset = LibriSpeech(training_params['db_path'], \"train\", model_params['n_feats'])\n",
    "    test_dataset =  LibriSpeech(training_params['db_path'], \"test\", model_params['n_feats'])\n",
    "\n",
    "    train_loader = get_dataloader(\n",
    "        train_dataset,\n",
    "        batch_size=training_params['batch_size'],\n",
    "        shuffle=True, use_cuda=use_cuda,\n",
    "        num_workers=num_workers\n",
    "    )\n",
    "    test_loader = get_dataloader(\n",
    "        test_dataset,\n",
    "        batch_size=training_params['batch_size'],\n",
    "        shuffle=False, use_cuda=use_cuda,\n",
    "        num_workers=num_workers\n",
    "    )\n",
    "\n",
    "    model = get_sr_model(SpeechRecognitionModel, model_params, device)\n",
    "\n",
    "    print('Num Model Parameters', sum([param.nelement() for param in model.parameters()]))\n",
    "\n",
    "    criterion = nn.CTCLoss(blank=28).to(device)\n",
    "    optimizer = optim.AdamW(model.parameters(), training_params['learning_rate'])\n",
    "    scheduler = optim.lr_scheduler.OneCycleLR(\n",
    "        optimizer,\n",
    "        max_lr=training_params['learning_rate'], \n",
    "        steps_per_epoch=int(len(train_loader)),\n",
    "        epochs=training_params['epochs'],\n",
    "        anneal_strategy='linear'\n",
    "    )\n",
    "\n",
    "    spath = training_params['weights_path']\n",
    "    if not os.path.isdir(spath):\n",
    "        os.makedirs(spath)\n",
    "\n",
    "\n",
    "    init_epoch = 1\n",
    "    iter_meter = IterMeter()\n",
    "\n",
    "    for epoch in range(init_epoch, training_params['epochs'] + 1):\n",
    "        t = time.time()\n",
    "        train(model, device, train_loader, criterion, optimizer, scheduler, epoch, iter_meter)\n",
    "        \n",
    "        if epoch % 5 == 0:\n",
    "            test(model, device, test_loader, criterion)\n",
    "            torch.save(model.state_dict(), spath + f'/model_{model_params[\"name\"]}_epoch_{epoch}.tar')\n",
    "            \n",
    "        print(f'Elapsed time {(time.time() - t)/60.0:.2f} minutes')"
   ],
   "metadata": {
    "id": "50Z-qMdc0VtM"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "anSrN_qBVdfL"
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "\"\"\"\n",
    "Use this code to train a model with a particular group of settings. Before\n",
    "changing any values make sure you understand what they are there for.\n",
    "\n",
    "You can try to vastly improve the CER,WER by using a predictive dictionary\n",
    "and fix miss-spellings in the model outputs.\n",
    "\"\"\"    \n",
    "torch.manual_seed(7)\n",
    "\n",
    "training_params = {\n",
    "    \"learning_rate\": 5e-4,\n",
    "    \"batch_size\": 10,\n",
    "    \"epochs\": 20,\n",
    "    \"db_path\": data_path,\n",
    "    \"weights_path\": data_path + \"/weights\"\n",
    "}\n",
    "\n",
    "rnn_params = {\n",
    "    'name': 'rnn',\n",
    "    \"n_cnn_layers\": 2,\n",
    "    \"n_rnn_layers\": 2,\n",
    "    \"rnn_dim\": 512,\n",
    "    \"n_class\": 29,\n",
    "    \"n_feats\": 128,\n",
    "    \"stride\": 2,\n",
    "    \"dropout\": 0.1,\n",
    "    \"use_gru\": False,\n",
    "    \"bidirectional\": False,\n",
    "}\n",
    "gru_params = rnn_params.copy()\n",
    "gru_params['name'] = 'gru'\n",
    "gru_params['use_gru'] = True\n",
    "\n",
    "bigru_params = gru_params.copy()\n",
    "bigru_params['name'] = 'bigru'\n",
    "bigru_params['bidirectional'] = True"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "models_params = [rnn_params, gru_params, bigru_params]\n",
    "# models_params = [gru_params, bigru_params]\n",
    "\n",
    "for params in models_params:\n",
    "    trainloop(params, training_params, device, use_cuda, num_workers=2)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xCt7Vg7S4FgK",
    "outputId": "f509210e-5ec1-4320-fd37-058fb7ee83f3"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Num Model Parameters 4518365\n",
      "Train Epoch: 1 lr = 2e-05\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/torchaudio/functional/functional.py:595: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (128) may be set too high. Or, the value for `n_freqs` (201) may be set too low.\n",
      "  \"At least one mel filterbank has all zero values. \"\n",
      "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  cpuset_checked))\n",
      "/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:1565: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train Epoch: 1 [0000/28539 (0%)]\tLoss: 7.200567\n",
      "Train Epoch: 1 [1000/28539 (4%)]\tLoss: 3.160992\n",
      "Train Epoch: 1 [2000/28539 (7%)]\tLoss: 2.937017\n",
      "Train Epoch: 1 [3000/28539 (11%)]\tLoss: 2.889538\n",
      "Train Epoch: 1 [4000/28539 (14%)]\tLoss: 2.862601\n",
      "Train Epoch: 1 [5000/28539 (18%)]\tLoss: 2.880747\n",
      "Train Epoch: 1 [6000/28539 (21%)]\tLoss: 2.803498\n",
      "Train Epoch: 1 [7000/28539 (25%)]\tLoss: 2.890071\n",
      "Train Epoch: 1 [8000/28539 (28%)]\tLoss: 2.837659\n",
      "Train Epoch: 1 [9000/28539 (32%)]\tLoss: 2.859166\n",
      "Train Epoch: 1 [10000/28539 (35%)]\tLoss: 2.892515\n",
      "Train Epoch: 1 [11000/28539 (39%)]\tLoss: 2.845295\n",
      "Train Epoch: 1 [12000/28539 (42%)]\tLoss: 2.852150\n",
      "Train Epoch: 1 [13000/28539 (46%)]\tLoss: 2.830335\n",
      "Train Epoch: 1 [14000/28539 (49%)]\tLoss: 2.878073\n",
      "Train Epoch: 1 [15000/28539 (53%)]\tLoss: 2.798177\n",
      "Train Epoch: 1 [16000/28539 (56%)]\tLoss: 2.802028\n",
      "Train Epoch: 1 [17000/28539 (60%)]\tLoss: 2.702271\n",
      "Train Epoch: 1 [18000/28539 (63%)]\tLoss: 2.561703\n",
      "Train Epoch: 1 [19000/28539 (67%)]\tLoss: 2.570950\n",
      "Train Epoch: 1 [20000/28539 (70%)]\tLoss: 2.340683\n",
      "Train Epoch: 1 [21000/28539 (74%)]\tLoss: 2.305954\n",
      "Train Epoch: 1 [22000/28539 (77%)]\tLoss: 2.455791\n",
      "Train Epoch: 1 [23000/28539 (81%)]\tLoss: 2.147149\n",
      "Train Epoch: 1 [24000/28539 (84%)]\tLoss: 2.098600\n",
      "Train Epoch: 1 [25000/28539 (88%)]\tLoss: 2.174951\n",
      "Train Epoch: 1 [26000/28539 (91%)]\tLoss: 2.024814\n",
      "Train Epoch: 1 [27000/28539 (95%)]\tLoss: 2.198159\n",
      "Train Epoch: 1 [28000/28539 (98%)]\tLoss: 1.973979\n",
      "Elapsed time 8.56 minutes\n",
      "Train Epoch: 2 lr = 0.00010000467207849092\n",
      "Train Epoch: 2 [0000/28539 (0%)]\tLoss: 1.908633\n",
      "Train Epoch: 2 [1000/28539 (4%)]\tLoss: 1.898515\n",
      "Train Epoch: 2 [2000/28539 (7%)]\tLoss: 1.910295\n",
      "Train Epoch: 2 [3000/28539 (11%)]\tLoss: 1.962902\n",
      "Train Epoch: 2 [4000/28539 (14%)]\tLoss: 1.980598\n",
      "Train Epoch: 2 [5000/28539 (18%)]\tLoss: 1.928972\n",
      "Train Epoch: 2 [6000/28539 (21%)]\tLoss: 1.746038\n",
      "Train Epoch: 2 [7000/28539 (25%)]\tLoss: 1.799406\n",
      "Train Epoch: 2 [8000/28539 (28%)]\tLoss: 1.736597\n",
      "Train Epoch: 2 [9000/28539 (32%)]\tLoss: 1.798080\n",
      "Train Epoch: 2 [10000/28539 (35%)]\tLoss: 1.677749\n",
      "Train Epoch: 2 [11000/28539 (39%)]\tLoss: 1.779699\n",
      "Train Epoch: 2 [12000/28539 (42%)]\tLoss: 1.653497\n",
      "Train Epoch: 2 [13000/28539 (46%)]\tLoss: 1.913947\n",
      "Train Epoch: 2 [14000/28539 (49%)]\tLoss: 1.748648\n",
      "Train Epoch: 2 [15000/28539 (53%)]\tLoss: 1.689989\n",
      "Train Epoch: 2 [16000/28539 (56%)]\tLoss: 1.726116\n",
      "Train Epoch: 2 [17000/28539 (60%)]\tLoss: 1.626878\n",
      "Train Epoch: 2 [18000/28539 (63%)]\tLoss: 1.592712\n",
      "Train Epoch: 2 [19000/28539 (67%)]\tLoss: 1.650675\n",
      "Train Epoch: 2 [20000/28539 (70%)]\tLoss: 1.640523\n",
      "Train Epoch: 2 [21000/28539 (74%)]\tLoss: 1.761458\n",
      "Train Epoch: 2 [22000/28539 (77%)]\tLoss: 1.692064\n",
      "Train Epoch: 2 [23000/28539 (81%)]\tLoss: 1.616692\n",
      "Train Epoch: 2 [24000/28539 (84%)]\tLoss: 1.637610\n",
      "Train Epoch: 2 [25000/28539 (88%)]\tLoss: 1.640817\n",
      "Train Epoch: 2 [26000/28539 (91%)]\tLoss: 1.572417\n",
      "Train Epoch: 2 [27000/28539 (95%)]\tLoss: 1.591924\n",
      "Train Epoch: 2 [28000/28539 (98%)]\tLoss: 1.553849\n",
      "Elapsed time 8.55 minutes\n",
      "Train Epoch: 3 lr = 0.00018000934415698185\n",
      "Train Epoch: 3 [0000/28539 (0%)]\tLoss: 1.544159\n",
      "Train Epoch: 3 [1000/28539 (4%)]\tLoss: 1.624378\n",
      "Train Epoch: 3 [2000/28539 (7%)]\tLoss: 1.720659\n",
      "Train Epoch: 3 [3000/28539 (11%)]\tLoss: 1.556367\n",
      "Train Epoch: 3 [4000/28539 (14%)]\tLoss: 1.522598\n",
      "Train Epoch: 3 [5000/28539 (18%)]\tLoss: 1.497122\n",
      "Train Epoch: 3 [6000/28539 (21%)]\tLoss: 1.392292\n",
      "Train Epoch: 3 [7000/28539 (25%)]\tLoss: 1.284360\n",
      "Train Epoch: 3 [8000/28539 (28%)]\tLoss: 1.385566\n",
      "Train Epoch: 3 [9000/28539 (32%)]\tLoss: 1.510334\n",
      "Train Epoch: 3 [10000/28539 (35%)]\tLoss: 1.504040\n",
      "Train Epoch: 3 [11000/28539 (39%)]\tLoss: 1.415483\n",
      "Train Epoch: 3 [12000/28539 (42%)]\tLoss: 1.348384\n",
      "Train Epoch: 3 [13000/28539 (46%)]\tLoss: 1.541872\n",
      "Train Epoch: 3 [14000/28539 (49%)]\tLoss: 1.622499\n",
      "Train Epoch: 3 [15000/28539 (53%)]\tLoss: 1.438921\n",
      "Train Epoch: 3 [16000/28539 (56%)]\tLoss: 1.349295\n",
      "Train Epoch: 3 [17000/28539 (60%)]\tLoss: 1.398963\n",
      "Train Epoch: 3 [18000/28539 (63%)]\tLoss: 1.345470\n",
      "Train Epoch: 3 [19000/28539 (67%)]\tLoss: 1.408639\n",
      "Train Epoch: 3 [20000/28539 (70%)]\tLoss: 1.493667\n",
      "Train Epoch: 3 [21000/28539 (74%)]\tLoss: 1.421612\n",
      "Train Epoch: 3 [22000/28539 (77%)]\tLoss: 1.389803\n",
      "Train Epoch: 3 [23000/28539 (81%)]\tLoss: 1.397835\n",
      "Train Epoch: 3 [24000/28539 (84%)]\tLoss: 1.343010\n",
      "Train Epoch: 3 [25000/28539 (88%)]\tLoss: 1.423020\n",
      "Train Epoch: 3 [26000/28539 (91%)]\tLoss: 1.549178\n",
      "Train Epoch: 3 [27000/28539 (95%)]\tLoss: 1.443095\n",
      "Train Epoch: 3 [28000/28539 (98%)]\tLoss: 1.193914\n",
      "Elapsed time 8.55 minutes\n",
      "Train Epoch: 4 lr = 0.00026001401623547275\n",
      "Train Epoch: 4 [0000/28539 (0%)]\tLoss: 1.239558\n",
      "Train Epoch: 4 [1000/28539 (4%)]\tLoss: 1.322880\n",
      "Train Epoch: 4 [2000/28539 (7%)]\tLoss: 1.278088\n",
      "Train Epoch: 4 [3000/28539 (11%)]\tLoss: 1.336385\n",
      "Train Epoch: 4 [4000/28539 (14%)]\tLoss: 1.314036\n",
      "Train Epoch: 4 [5000/28539 (18%)]\tLoss: 1.620417\n",
      "Train Epoch: 4 [6000/28539 (21%)]\tLoss: 1.406672\n",
      "Train Epoch: 4 [7000/28539 (25%)]\tLoss: 1.188461\n",
      "Train Epoch: 4 [8000/28539 (28%)]\tLoss: 1.261772\n",
      "Train Epoch: 4 [9000/28539 (32%)]\tLoss: 1.202173\n",
      "Train Epoch: 4 [10000/28539 (35%)]\tLoss: 1.291358\n",
      "Train Epoch: 4 [11000/28539 (39%)]\tLoss: 1.234868\n",
      "Train Epoch: 4 [12000/28539 (42%)]\tLoss: 1.177048\n",
      "Train Epoch: 4 [13000/28539 (46%)]\tLoss: 1.287244\n",
      "Train Epoch: 4 [14000/28539 (49%)]\tLoss: 1.384175\n",
      "Train Epoch: 4 [15000/28539 (53%)]\tLoss: 1.223945\n",
      "Train Epoch: 4 [16000/28539 (56%)]\tLoss: 1.422260\n",
      "Train Epoch: 4 [17000/28539 (60%)]\tLoss: 1.220768\n",
      "Train Epoch: 4 [18000/28539 (63%)]\tLoss: 1.157435\n",
      "Train Epoch: 4 [19000/28539 (67%)]\tLoss: 1.225002\n",
      "Train Epoch: 4 [20000/28539 (70%)]\tLoss: 1.340812\n",
      "Train Epoch: 4 [21000/28539 (74%)]\tLoss: 1.262800\n",
      "Train Epoch: 4 [22000/28539 (77%)]\tLoss: 1.189554\n",
      "Train Epoch: 4 [23000/28539 (81%)]\tLoss: 1.165634\n",
      "Train Epoch: 4 [24000/28539 (84%)]\tLoss: 1.283088\n",
      "Train Epoch: 4 [25000/28539 (88%)]\tLoss: 1.317597\n",
      "Train Epoch: 4 [26000/28539 (91%)]\tLoss: 1.182052\n",
      "Train Epoch: 4 [27000/28539 (95%)]\tLoss: 1.310474\n",
      "Train Epoch: 4 [28000/28539 (98%)]\tLoss: 1.243926\n",
      "Elapsed time 8.55 minutes\n",
      "Train Epoch: 5 lr = 0.0003400186883139637\n",
      "Train Epoch: 5 [0000/28539 (0%)]\tLoss: 1.182805\n",
      "Train Epoch: 5 [1000/28539 (4%)]\tLoss: 1.267060\n",
      "Train Epoch: 5 [2000/28539 (7%)]\tLoss: 1.293075\n",
      "Train Epoch: 5 [3000/28539 (11%)]\tLoss: 1.329800\n",
      "Train Epoch: 5 [4000/28539 (14%)]\tLoss: 1.314554\n",
      "Train Epoch: 5 [5000/28539 (18%)]\tLoss: 1.474320\n",
      "Train Epoch: 5 [6000/28539 (21%)]\tLoss: 1.300919\n",
      "Train Epoch: 5 [7000/28539 (25%)]\tLoss: 1.231501\n",
      "Train Epoch: 5 [8000/28539 (28%)]\tLoss: 1.283451\n",
      "Train Epoch: 5 [9000/28539 (32%)]\tLoss: 1.194614\n",
      "Train Epoch: 5 [10000/28539 (35%)]\tLoss: 1.260400\n",
      "Train Epoch: 5 [11000/28539 (39%)]\tLoss: 1.148529\n",
      "Train Epoch: 5 [12000/28539 (42%)]\tLoss: 1.140182\n",
      "Train Epoch: 5 [13000/28539 (46%)]\tLoss: 1.205154\n",
      "Train Epoch: 5 [14000/28539 (49%)]\tLoss: 1.170036\n",
      "Train Epoch: 5 [15000/28539 (53%)]\tLoss: 1.215225\n",
      "Train Epoch: 5 [16000/28539 (56%)]\tLoss: 1.176884\n",
      "Train Epoch: 5 [17000/28539 (60%)]\tLoss: 1.100561\n",
      "Train Epoch: 5 [18000/28539 (63%)]\tLoss: 1.295364\n",
      "Train Epoch: 5 [19000/28539 (67%)]\tLoss: 1.227826\n",
      "Train Epoch: 5 [20000/28539 (70%)]\tLoss: 1.049415\n",
      "Train Epoch: 5 [21000/28539 (74%)]\tLoss: 1.179943\n",
      "Train Epoch: 5 [22000/28539 (77%)]\tLoss: 1.273868\n",
      "Train Epoch: 5 [23000/28539 (81%)]\tLoss: 1.330312\n",
      "Train Epoch: 5 [24000/28539 (84%)]\tLoss: 1.045445\n",
      "Train Epoch: 5 [25000/28539 (88%)]\tLoss: 1.088949\n",
      "Train Epoch: 5 [26000/28539 (91%)]\tLoss: 1.268208\n",
      "Train Epoch: 5 [27000/28539 (95%)]\tLoss: 1.114008\n",
      "Train Epoch: 5 [28000/28539 (98%)]\tLoss: 1.146014\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Test set: Average loss: 0.9679, Average CER: 0.297197 Average WER: 0.7659\n",
      "\n",
      "\n",
      "EXAMPLE\n",
      "GT:\n",
      "i love thee with a love i seemed to lose with my lost saints i love thee with the breath smiles tears of all my life and if god choose i shall but love thee better after death\n",
      "\n",
      "Network output:\n",
      "i  loved the with a loe i seened to the with mi lost sas i love the with the brah smils  e ars af aho mialife and if ga ches i shol but loved the batter after dah\n",
      "Elapsed time 14.61 minutes\n",
      "Train Epoch: 6 lr = 0.0004200233603924546\n",
      "Train Epoch: 6 [0000/28539 (0%)]\tLoss: 1.185221\n",
      "Train Epoch: 6 [1000/28539 (4%)]\tLoss: 1.050303\n",
      "Train Epoch: 6 [2000/28539 (7%)]\tLoss: 1.104402\n",
      "Train Epoch: 6 [3000/28539 (11%)]\tLoss: 1.311977\n",
      "Train Epoch: 6 [4000/28539 (14%)]\tLoss: 1.106704\n",
      "Train Epoch: 6 [5000/28539 (18%)]\tLoss: 1.144588\n",
      "Train Epoch: 6 [6000/28539 (21%)]\tLoss: 1.061289\n",
      "Train Epoch: 6 [7000/28539 (25%)]\tLoss: 1.172609\n",
      "Train Epoch: 6 [8000/28539 (28%)]\tLoss: 1.260123\n",
      "Train Epoch: 6 [9000/28539 (32%)]\tLoss: 1.099229\n",
      "Train Epoch: 6 [10000/28539 (35%)]\tLoss: 1.161150\n",
      "Train Epoch: 6 [11000/28539 (39%)]\tLoss: 1.283360\n",
      "Train Epoch: 6 [12000/28539 (42%)]\tLoss: 1.092991\n",
      "Train Epoch: 6 [13000/28539 (46%)]\tLoss: 1.329159\n",
      "Train Epoch: 6 [14000/28539 (49%)]\tLoss: 1.061076\n",
      "Train Epoch: 6 [15000/28539 (53%)]\tLoss: 1.172192\n",
      "Train Epoch: 6 [16000/28539 (56%)]\tLoss: 1.237018\n",
      "Train Epoch: 6 [17000/28539 (60%)]\tLoss: 1.216177\n",
      "Train Epoch: 6 [18000/28539 (63%)]\tLoss: 1.095178\n",
      "Train Epoch: 6 [19000/28539 (67%)]\tLoss: 1.178102\n",
      "Train Epoch: 6 [20000/28539 (70%)]\tLoss: 1.104159\n",
      "Train Epoch: 6 [21000/28539 (74%)]\tLoss: 0.968783\n",
      "Train Epoch: 6 [22000/28539 (77%)]\tLoss: 1.086217\n",
      "Train Epoch: 6 [23000/28539 (81%)]\tLoss: 1.059765\n",
      "Train Epoch: 6 [24000/28539 (84%)]\tLoss: 1.485940\n",
      "Train Epoch: 6 [25000/28539 (88%)]\tLoss: 1.342075\n",
      "Train Epoch: 6 [26000/28539 (91%)]\tLoss: 1.249245\n",
      "Train Epoch: 6 [27000/28539 (95%)]\tLoss: 1.135093\n",
      "Train Epoch: 6 [28000/28539 (98%)]\tLoss: 1.152321\n",
      "Elapsed time 8.57 minutes\n",
      "Train Epoch: 7 lr = 0.0004999874862849134\n",
      "Train Epoch: 7 [0000/28539 (0%)]\tLoss: 1.179957\n",
      "Train Epoch: 7 [1000/28539 (4%)]\tLoss: 0.995357\n",
      "Train Epoch: 7 [2000/28539 (7%)]\tLoss: 1.020430\n",
      "Train Epoch: 7 [3000/28539 (11%)]\tLoss: 1.103514\n",
      "Train Epoch: 7 [4000/28539 (14%)]\tLoss: 1.206251\n",
      "Train Epoch: 7 [5000/28539 (18%)]\tLoss: 1.290082\n",
      "Train Epoch: 7 [6000/28539 (21%)]\tLoss: 1.121539\n",
      "Train Epoch: 7 [7000/28539 (25%)]\tLoss: 1.091773\n",
      "Train Epoch: 7 [8000/28539 (28%)]\tLoss: 1.168569\n",
      "Train Epoch: 7 [9000/28539 (32%)]\tLoss: 1.256651\n",
      "Train Epoch: 7 [10000/28539 (35%)]\tLoss: 1.055987\n",
      "Train Epoch: 7 [11000/28539 (39%)]\tLoss: 1.098921\n",
      "Train Epoch: 7 [12000/28539 (42%)]\tLoss: 1.006976\n",
      "Train Epoch: 7 [13000/28539 (46%)]\tLoss: 1.115329\n",
      "Train Epoch: 7 [14000/28539 (49%)]\tLoss: 1.189086\n",
      "Train Epoch: 7 [15000/28539 (53%)]\tLoss: 1.066200\n",
      "Train Epoch: 7 [16000/28539 (56%)]\tLoss: 1.121320\n",
      "Train Epoch: 7 [17000/28539 (60%)]\tLoss: 1.061986\n",
      "Train Epoch: 7 [18000/28539 (63%)]\tLoss: 0.975055\n",
      "Train Epoch: 7 [19000/28539 (67%)]\tLoss: 1.107694\n",
      "Train Epoch: 7 [20000/28539 (70%)]\tLoss: 1.103973\n",
      "Train Epoch: 7 [21000/28539 (74%)]\tLoss: 1.160980\n",
      "Train Epoch: 7 [22000/28539 (77%)]\tLoss: 1.020516\n",
      "Train Epoch: 7 [23000/28539 (81%)]\tLoss: 1.055738\n",
      "Train Epoch: 7 [24000/28539 (84%)]\tLoss: 1.132337\n",
      "Train Epoch: 7 [25000/28539 (88%)]\tLoss: 0.949661\n",
      "Train Epoch: 7 [26000/28539 (91%)]\tLoss: 1.122181\n",
      "Train Epoch: 7 [27000/28539 (95%)]\tLoss: 1.109064\n",
      "Train Epoch: 7 [28000/28539 (98%)]\tLoss: 1.082764\n",
      "Elapsed time 8.56 minutes\n",
      "Train Epoch: 8 lr = 0.00046427334342777056\n",
      "Train Epoch: 8 [0000/28539 (0%)]\tLoss: 0.959870\n",
      "Train Epoch: 8 [1000/28539 (4%)]\tLoss: 1.055022\n",
      "Train Epoch: 8 [2000/28539 (7%)]\tLoss: 1.054529\n",
      "Train Epoch: 8 [3000/28539 (11%)]\tLoss: 1.112622\n",
      "Train Epoch: 8 [4000/28539 (14%)]\tLoss: 0.923652\n",
      "Train Epoch: 8 [5000/28539 (18%)]\tLoss: 0.993775\n",
      "Train Epoch: 8 [6000/28539 (21%)]\tLoss: 1.043429\n",
      "Train Epoch: 8 [7000/28539 (25%)]\tLoss: 1.063225\n",
      "Train Epoch: 8 [8000/28539 (28%)]\tLoss: 1.038653\n",
      "Train Epoch: 8 [9000/28539 (32%)]\tLoss: 0.970433\n",
      "Train Epoch: 8 [10000/28539 (35%)]\tLoss: 1.097557\n",
      "Train Epoch: 8 [11000/28539 (39%)]\tLoss: 0.999099\n",
      "Train Epoch: 8 [12000/28539 (42%)]\tLoss: 0.972950\n",
      "Train Epoch: 8 [13000/28539 (46%)]\tLoss: 0.918190\n",
      "Train Epoch: 8 [14000/28539 (49%)]\tLoss: 0.970795\n",
      "Train Epoch: 8 [15000/28539 (53%)]\tLoss: 1.089283\n",
      "Train Epoch: 8 [16000/28539 (56%)]\tLoss: 0.836682\n",
      "Train Epoch: 8 [17000/28539 (60%)]\tLoss: 1.046962\n",
      "Train Epoch: 8 [18000/28539 (63%)]\tLoss: 1.079954\n",
      "Train Epoch: 8 [19000/28539 (67%)]\tLoss: 1.110703\n",
      "Train Epoch: 8 [20000/28539 (70%)]\tLoss: 1.010981\n",
      "Train Epoch: 8 [21000/28539 (74%)]\tLoss: 1.074723\n",
      "Train Epoch: 8 [22000/28539 (77%)]\tLoss: 0.864288\n",
      "Train Epoch: 8 [23000/28539 (81%)]\tLoss: 0.953683\n",
      "Train Epoch: 8 [24000/28539 (84%)]\tLoss: 1.199557\n",
      "Train Epoch: 8 [25000/28539 (88%)]\tLoss: 0.937618\n",
      "Train Epoch: 8 [26000/28539 (91%)]\tLoss: 0.973089\n",
      "Train Epoch: 8 [27000/28539 (95%)]\tLoss: 0.993184\n",
      "Train Epoch: 8 [28000/28539 (98%)]\tLoss: 0.863126\n",
      "Elapsed time 8.56 minutes\n",
      "Train Epoch: 9 lr = 0.0004285592005706277\n",
      "Train Epoch: 9 [0000/28539 (0%)]\tLoss: 1.043066\n",
      "Train Epoch: 9 [1000/28539 (4%)]\tLoss: 1.040180\n",
      "Train Epoch: 9 [2000/28539 (7%)]\tLoss: 1.173927\n",
      "Train Epoch: 9 [3000/28539 (11%)]\tLoss: 0.997199\n",
      "Train Epoch: 9 [4000/28539 (14%)]\tLoss: 0.959252\n",
      "Train Epoch: 9 [5000/28539 (18%)]\tLoss: 1.023219\n",
      "Train Epoch: 9 [6000/28539 (21%)]\tLoss: 0.995818\n",
      "Train Epoch: 9 [7000/28539 (25%)]\tLoss: 0.955610\n",
      "Train Epoch: 9 [8000/28539 (28%)]\tLoss: 0.921699\n",
      "Train Epoch: 9 [9000/28539 (32%)]\tLoss: 0.920156\n",
      "Train Epoch: 9 [10000/28539 (35%)]\tLoss: 0.852196\n",
      "Train Epoch: 9 [11000/28539 (39%)]\tLoss: 0.866143\n",
      "Train Epoch: 9 [12000/28539 (42%)]\tLoss: 0.933393\n",
      "Train Epoch: 9 [13000/28539 (46%)]\tLoss: 0.909317\n",
      "Train Epoch: 9 [14000/28539 (49%)]\tLoss: 0.817668\n",
      "Train Epoch: 9 [15000/28539 (53%)]\tLoss: 0.766248\n",
      "Train Epoch: 9 [16000/28539 (56%)]\tLoss: 1.080764\n",
      "Train Epoch: 9 [17000/28539 (60%)]\tLoss: 1.012227\n",
      "Train Epoch: 9 [18000/28539 (63%)]\tLoss: 1.052726\n",
      "Train Epoch: 9 [19000/28539 (67%)]\tLoss: 0.876999\n",
      "Train Epoch: 9 [20000/28539 (70%)]\tLoss: 0.966218\n",
      "Train Epoch: 9 [21000/28539 (74%)]\tLoss: 0.918341\n",
      "Train Epoch: 9 [22000/28539 (77%)]\tLoss: 0.852055\n",
      "Train Epoch: 9 [23000/28539 (81%)]\tLoss: 0.852224\n",
      "Train Epoch: 9 [24000/28539 (84%)]\tLoss: 0.896573\n",
      "Train Epoch: 9 [25000/28539 (88%)]\tLoss: 0.869379\n",
      "Train Epoch: 9 [26000/28539 (91%)]\tLoss: 1.026889\n",
      "Train Epoch: 9 [27000/28539 (95%)]\tLoss: 0.889163\n",
      "Train Epoch: 9 [28000/28539 (98%)]\tLoss: 0.958372\n",
      "Elapsed time 8.56 minutes\n",
      "Train Epoch: 10 lr = 0.0003928450577134848\n",
      "Train Epoch: 10 [0000/28539 (0%)]\tLoss: 0.947824\n",
      "Train Epoch: 10 [1000/28539 (4%)]\tLoss: 0.878159\n",
      "Train Epoch: 10 [2000/28539 (7%)]\tLoss: 0.912468\n",
      "Train Epoch: 10 [3000/28539 (11%)]\tLoss: 1.016066\n",
      "Train Epoch: 10 [4000/28539 (14%)]\tLoss: 0.978879\n",
      "Train Epoch: 10 [5000/28539 (18%)]\tLoss: 0.954233\n",
      "Train Epoch: 10 [6000/28539 (21%)]\tLoss: 0.714944\n",
      "Train Epoch: 10 [7000/28539 (25%)]\tLoss: 1.007114\n",
      "Train Epoch: 10 [8000/28539 (28%)]\tLoss: 0.788202\n",
      "Train Epoch: 10 [9000/28539 (32%)]\tLoss: 0.886610\n",
      "Train Epoch: 10 [10000/28539 (35%)]\tLoss: 1.002227\n",
      "Train Epoch: 10 [11000/28539 (39%)]\tLoss: 0.928667\n",
      "Train Epoch: 10 [12000/28539 (42%)]\tLoss: 0.772110\n",
      "Train Epoch: 10 [13000/28539 (46%)]\tLoss: 0.836125\n",
      "Train Epoch: 10 [14000/28539 (49%)]\tLoss: 0.947905\n",
      "Train Epoch: 10 [15000/28539 (53%)]\tLoss: 0.907287\n",
      "Train Epoch: 10 [16000/28539 (56%)]\tLoss: 0.858103\n",
      "Train Epoch: 10 [17000/28539 (60%)]\tLoss: 0.841769\n",
      "Train Epoch: 10 [18000/28539 (63%)]\tLoss: 0.899983\n",
      "Train Epoch: 10 [19000/28539 (67%)]\tLoss: 0.989768\n",
      "Train Epoch: 10 [20000/28539 (70%)]\tLoss: 0.820222\n",
      "Train Epoch: 10 [21000/28539 (74%)]\tLoss: 0.957271\n",
      "Train Epoch: 10 [22000/28539 (77%)]\tLoss: 0.798550\n",
      "Train Epoch: 10 [23000/28539 (81%)]\tLoss: 0.776000\n",
      "Train Epoch: 10 [24000/28539 (84%)]\tLoss: 0.963747\n",
      "Train Epoch: 10 [25000/28539 (88%)]\tLoss: 0.998664\n",
      "Train Epoch: 10 [26000/28539 (91%)]\tLoss: 0.854257\n",
      "Train Epoch: 10 [27000/28539 (95%)]\tLoss: 0.904979\n",
      "Train Epoch: 10 [28000/28539 (98%)]\tLoss: 0.882303\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Test set: Average loss: 0.7418, Average CER: 0.227845 Average WER: 0.6602\n",
      "\n",
      "\n",
      "EXAMPLE\n",
      "GT:\n",
      "i love thee with a love i seemed to lose with my lost saints i love thee with the breath smiles tears of all my life and if god choose i shall but love thee better after death\n",
      "\n",
      "Network output:\n",
      "i leve the with a love i seemed to le with mi lost sans i aloved b with the brath smales t ars of all mialihe and if gar ches i shalwl but loved the better after dath\n",
      "Elapsed time 14.84 minutes\n",
      "Train Epoch: 11 lr = 0.000357130914856342\n",
      "Train Epoch: 11 [0000/28539 (0%)]\tLoss: 0.979119\n",
      "Train Epoch: 11 [1000/28539 (4%)]\tLoss: 0.705329\n",
      "Train Epoch: 11 [2000/28539 (7%)]\tLoss: 1.024356\n",
      "Train Epoch: 11 [3000/28539 (11%)]\tLoss: 0.869062\n",
      "Train Epoch: 11 [4000/28539 (14%)]\tLoss: 0.854122\n",
      "Train Epoch: 11 [5000/28539 (18%)]\tLoss: 0.866720\n",
      "Train Epoch: 11 [6000/28539 (21%)]\tLoss: 0.912990\n",
      "Train Epoch: 11 [7000/28539 (25%)]\tLoss: 0.896406\n",
      "Train Epoch: 11 [8000/28539 (28%)]\tLoss: 0.774498\n",
      "Train Epoch: 11 [9000/28539 (32%)]\tLoss: 0.818587\n",
      "Train Epoch: 11 [10000/28539 (35%)]\tLoss: 0.927353\n",
      "Train Epoch: 11 [11000/28539 (39%)]\tLoss: 0.945692\n",
      "Train Epoch: 11 [12000/28539 (42%)]\tLoss: 0.932495\n",
      "Train Epoch: 11 [13000/28539 (46%)]\tLoss: 0.821334\n",
      "Train Epoch: 11 [14000/28539 (49%)]\tLoss: 0.854888\n",
      "Train Epoch: 11 [15000/28539 (53%)]\tLoss: 0.961995\n",
      "Train Epoch: 11 [16000/28539 (56%)]\tLoss: 1.075644\n",
      "Train Epoch: 11 [17000/28539 (60%)]\tLoss: 0.840499\n",
      "Train Epoch: 11 [18000/28539 (63%)]\tLoss: 0.934447\n",
      "Train Epoch: 11 [19000/28539 (67%)]\tLoss: 0.848974\n",
      "Train Epoch: 11 [20000/28539 (70%)]\tLoss: 0.943443\n",
      "Train Epoch: 11 [21000/28539 (74%)]\tLoss: 0.936809\n",
      "Train Epoch: 11 [22000/28539 (77%)]\tLoss: 0.956524\n",
      "Train Epoch: 11 [23000/28539 (81%)]\tLoss: 0.777427\n",
      "Train Epoch: 11 [24000/28539 (84%)]\tLoss: 0.862491\n",
      "Train Epoch: 11 [25000/28539 (88%)]\tLoss: 0.807497\n",
      "Train Epoch: 11 [26000/28539 (91%)]\tLoss: 0.872478\n",
      "Train Epoch: 11 [27000/28539 (95%)]\tLoss: 0.973685\n",
      "Train Epoch: 11 [28000/28539 (98%)]\tLoss: 0.844576\n",
      "Elapsed time 8.56 minutes\n",
      "Train Epoch: 12 lr = 0.0003214167719991991\n",
      "Train Epoch: 12 [0000/28539 (0%)]\tLoss: 0.712203\n",
      "Train Epoch: 12 [1000/28539 (4%)]\tLoss: 0.854966\n",
      "Train Epoch: 12 [2000/28539 (7%)]\tLoss: 0.751019\n",
      "Train Epoch: 12 [3000/28539 (11%)]\tLoss: 1.054847\n",
      "Train Epoch: 12 [4000/28539 (14%)]\tLoss: 0.787876\n",
      "Train Epoch: 12 [5000/28539 (18%)]\tLoss: 1.027920\n",
      "Train Epoch: 12 [6000/28539 (21%)]\tLoss: 0.849018\n",
      "Train Epoch: 12 [7000/28539 (25%)]\tLoss: 0.748766\n",
      "Train Epoch: 12 [8000/28539 (28%)]\tLoss: 0.927222\n",
      "Train Epoch: 12 [9000/28539 (32%)]\tLoss: 0.966747\n",
      "Train Epoch: 12 [10000/28539 (35%)]\tLoss: 0.848841\n",
      "Train Epoch: 12 [11000/28539 (39%)]\tLoss: 0.915252\n",
      "Train Epoch: 12 [12000/28539 (42%)]\tLoss: 0.836689\n",
      "Train Epoch: 12 [13000/28539 (46%)]\tLoss: 0.911709\n",
      "Train Epoch: 12 [14000/28539 (49%)]\tLoss: 0.826658\n",
      "Train Epoch: 12 [15000/28539 (53%)]\tLoss: 0.649369\n",
      "Train Epoch: 12 [16000/28539 (56%)]\tLoss: 0.878905\n",
      "Train Epoch: 12 [17000/28539 (60%)]\tLoss: 1.055046\n",
      "Train Epoch: 12 [18000/28539 (63%)]\tLoss: 0.753714\n",
      "Train Epoch: 12 [19000/28539 (67%)]\tLoss: 0.697360\n",
      "Train Epoch: 12 [20000/28539 (70%)]\tLoss: 0.848577\n",
      "Train Epoch: 12 [21000/28539 (74%)]\tLoss: 0.840535\n",
      "Train Epoch: 12 [22000/28539 (77%)]\tLoss: 0.857783\n",
      "Train Epoch: 12 [23000/28539 (81%)]\tLoss: 0.888931\n",
      "Train Epoch: 12 [24000/28539 (84%)]\tLoss: 0.890679\n",
      "Train Epoch: 12 [25000/28539 (88%)]\tLoss: 0.815960\n",
      "Train Epoch: 12 [26000/28539 (91%)]\tLoss: 0.778407\n",
      "Train Epoch: 12 [27000/28539 (95%)]\tLoss: 0.841993\n",
      "Train Epoch: 12 [28000/28539 (98%)]\tLoss: 0.830001\n",
      "Elapsed time 8.56 minutes\n",
      "Train Epoch: 13 lr = 0.00028570262914205625\n",
      "Train Epoch: 13 [0000/28539 (0%)]\tLoss: 0.868904\n",
      "Train Epoch: 13 [1000/28539 (4%)]\tLoss: 0.785340\n",
      "Train Epoch: 13 [2000/28539 (7%)]\tLoss: 0.968333\n",
      "Train Epoch: 13 [3000/28539 (11%)]\tLoss: 1.094611\n",
      "Train Epoch: 13 [4000/28539 (14%)]\tLoss: 0.805250\n",
      "Train Epoch: 13 [5000/28539 (18%)]\tLoss: 0.755245\n",
      "Train Epoch: 13 [6000/28539 (21%)]\tLoss: 0.843803\n",
      "Train Epoch: 13 [7000/28539 (25%)]\tLoss: 0.859746\n",
      "Train Epoch: 13 [8000/28539 (28%)]\tLoss: 0.803364\n",
      "Train Epoch: 13 [9000/28539 (32%)]\tLoss: 0.786290\n",
      "Train Epoch: 13 [10000/28539 (35%)]\tLoss: 0.847773\n",
      "Train Epoch: 13 [11000/28539 (39%)]\tLoss: 0.662199\n",
      "Train Epoch: 13 [12000/28539 (42%)]\tLoss: 0.733680\n",
      "Train Epoch: 13 [13000/28539 (46%)]\tLoss: 1.112113\n",
      "Train Epoch: 13 [14000/28539 (49%)]\tLoss: 0.719119\n",
      "Train Epoch: 13 [15000/28539 (53%)]\tLoss: 0.879344\n",
      "Train Epoch: 13 [16000/28539 (56%)]\tLoss: 0.771655\n",
      "Train Epoch: 13 [17000/28539 (60%)]\tLoss: 0.768919\n",
      "Train Epoch: 13 [18000/28539 (63%)]\tLoss: 0.891192\n",
      "Train Epoch: 13 [19000/28539 (67%)]\tLoss: 0.809419\n",
      "Train Epoch: 13 [20000/28539 (70%)]\tLoss: 0.620462\n",
      "Train Epoch: 13 [21000/28539 (74%)]\tLoss: 0.830933\n",
      "Train Epoch: 13 [22000/28539 (77%)]\tLoss: 0.871867\n",
      "Train Epoch: 13 [23000/28539 (81%)]\tLoss: 0.820615\n",
      "Train Epoch: 13 [24000/28539 (84%)]\tLoss: 0.746749\n",
      "Train Epoch: 13 [25000/28539 (88%)]\tLoss: 0.808823\n",
      "Train Epoch: 13 [26000/28539 (91%)]\tLoss: 0.754876\n",
      "Train Epoch: 13 [27000/28539 (95%)]\tLoss: 0.920979\n",
      "Train Epoch: 13 [28000/28539 (98%)]\tLoss: 0.653093\n",
      "Elapsed time 8.55 minutes\n",
      "Train Epoch: 14 lr = 0.0002499884862849134\n",
      "Train Epoch: 14 [0000/28539 (0%)]\tLoss: 0.646931\n",
      "Train Epoch: 14 [1000/28539 (4%)]\tLoss: 0.712472\n",
      "Train Epoch: 14 [2000/28539 (7%)]\tLoss: 0.826932\n",
      "Train Epoch: 14 [3000/28539 (11%)]\tLoss: 0.880571\n",
      "Train Epoch: 14 [4000/28539 (14%)]\tLoss: 0.693264\n",
      "Train Epoch: 14 [5000/28539 (18%)]\tLoss: 0.740071\n",
      "Train Epoch: 14 [6000/28539 (21%)]\tLoss: 0.957993\n",
      "Train Epoch: 14 [7000/28539 (25%)]\tLoss: 0.801797\n",
      "Train Epoch: 14 [8000/28539 (28%)]\tLoss: 0.842097\n",
      "Train Epoch: 14 [9000/28539 (32%)]\tLoss: 0.995542\n",
      "Train Epoch: 14 [10000/28539 (35%)]\tLoss: 0.774624\n",
      "Train Epoch: 14 [11000/28539 (39%)]\tLoss: 0.782513\n",
      "Train Epoch: 14 [12000/28539 (42%)]\tLoss: 0.787498\n",
      "Train Epoch: 14 [13000/28539 (46%)]\tLoss: 0.857380\n",
      "Train Epoch: 14 [14000/28539 (49%)]\tLoss: 0.788504\n",
      "Train Epoch: 14 [15000/28539 (53%)]\tLoss: 0.778598\n",
      "Train Epoch: 14 [16000/28539 (56%)]\tLoss: 0.768768\n",
      "Train Epoch: 14 [17000/28539 (60%)]\tLoss: 0.938752\n",
      "Train Epoch: 14 [18000/28539 (63%)]\tLoss: 0.902796\n",
      "Train Epoch: 14 [19000/28539 (67%)]\tLoss: 0.728811\n",
      "Train Epoch: 14 [20000/28539 (70%)]\tLoss: 0.839838\n",
      "Train Epoch: 14 [21000/28539 (74%)]\tLoss: 0.903186\n",
      "Train Epoch: 14 [22000/28539 (77%)]\tLoss: 0.845712\n",
      "Train Epoch: 14 [23000/28539 (81%)]\tLoss: 0.754128\n",
      "Train Epoch: 14 [24000/28539 (84%)]\tLoss: 0.813200\n",
      "Train Epoch: 14 [25000/28539 (88%)]\tLoss: 0.959678\n",
      "Train Epoch: 14 [26000/28539 (91%)]\tLoss: 1.035106\n",
      "Train Epoch: 14 [27000/28539 (95%)]\tLoss: 0.983754\n",
      "Train Epoch: 14 [28000/28539 (98%)]\tLoss: 0.622889\n",
      "Elapsed time 8.54 minutes\n",
      "Train Epoch: 15 lr = 0.00021427434342777057\n",
      "Train Epoch: 15 [0000/28539 (0%)]\tLoss: 0.733508\n",
      "Train Epoch: 15 [1000/28539 (4%)]\tLoss: 0.784903\n",
      "Train Epoch: 15 [2000/28539 (7%)]\tLoss: 0.874624\n",
      "Train Epoch: 15 [3000/28539 (11%)]\tLoss: 0.864752\n",
      "Train Epoch: 15 [4000/28539 (14%)]\tLoss: 0.780646\n",
      "Train Epoch: 15 [5000/28539 (18%)]\tLoss: 0.824758\n",
      "Train Epoch: 15 [6000/28539 (21%)]\tLoss: 0.778999\n",
      "Train Epoch: 15 [7000/28539 (25%)]\tLoss: 0.743576\n",
      "Train Epoch: 15 [8000/28539 (28%)]\tLoss: 0.869595\n",
      "Train Epoch: 15 [9000/28539 (32%)]\tLoss: 0.862310\n",
      "Train Epoch: 15 [10000/28539 (35%)]\tLoss: 0.728528\n",
      "Train Epoch: 15 [11000/28539 (39%)]\tLoss: 0.789555\n",
      "Train Epoch: 15 [12000/28539 (42%)]\tLoss: 0.778027\n",
      "Train Epoch: 15 [13000/28539 (46%)]\tLoss: 0.861351\n",
      "Train Epoch: 15 [14000/28539 (49%)]\tLoss: 0.716907\n",
      "Train Epoch: 15 [15000/28539 (53%)]\tLoss: 0.761410\n",
      "Train Epoch: 15 [16000/28539 (56%)]\tLoss: 0.712780\n",
      "Train Epoch: 15 [17000/28539 (60%)]\tLoss: 0.722363\n",
      "Train Epoch: 15 [18000/28539 (63%)]\tLoss: 0.803873\n",
      "Train Epoch: 15 [19000/28539 (67%)]\tLoss: 0.629949\n",
      "Train Epoch: 15 [20000/28539 (70%)]\tLoss: 0.781984\n",
      "Train Epoch: 15 [21000/28539 (74%)]\tLoss: 0.730428\n",
      "Train Epoch: 15 [22000/28539 (77%)]\tLoss: 0.845799\n",
      "Train Epoch: 15 [23000/28539 (81%)]\tLoss: 0.935817\n",
      "Train Epoch: 15 [24000/28539 (84%)]\tLoss: 0.697696\n",
      "Train Epoch: 15 [25000/28539 (88%)]\tLoss: 0.704379\n",
      "Train Epoch: 15 [26000/28539 (91%)]\tLoss: 0.740692\n",
      "Train Epoch: 15 [27000/28539 (95%)]\tLoss: 0.920858\n",
      "Train Epoch: 15 [28000/28539 (98%)]\tLoss: 0.804506\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Test set: Average loss: 0.6529, Average CER: 0.196080 Average WER: 0.5805\n",
      "\n",
      "\n",
      "EXAMPLE\n",
      "GT:\n",
      "i love thee with a love i seemed to lose with my lost saints i love thee with the breath smiles tears of all my life and if god choose i shall but love thee better after death\n",
      "\n",
      "Network output:\n",
      "i leve the with a love i seened to los with mi lost sans i love be with the breat smales ers of al mi alife and if gad cshes i shall but love the better after dath\n",
      "Elapsed time 14.80 minutes\n",
      "Train Epoch: 16 lr = 0.00017856020057062773\n",
      "Train Epoch: 16 [0000/28539 (0%)]\tLoss: 0.746416\n",
      "Train Epoch: 16 [1000/28539 (4%)]\tLoss: 0.716373\n",
      "Train Epoch: 16 [2000/28539 (7%)]\tLoss: 0.684845\n",
      "Train Epoch: 16 [3000/28539 (11%)]\tLoss: 0.843258\n",
      "Train Epoch: 16 [4000/28539 (14%)]\tLoss: 0.785305\n",
      "Train Epoch: 16 [5000/28539 (18%)]\tLoss: 0.696516\n",
      "Train Epoch: 16 [6000/28539 (21%)]\tLoss: 0.695907\n",
      "Train Epoch: 16 [7000/28539 (25%)]\tLoss: 0.894420\n",
      "Train Epoch: 16 [8000/28539 (28%)]\tLoss: 0.684529\n",
      "Train Epoch: 16 [9000/28539 (32%)]\tLoss: 0.924282\n",
      "Train Epoch: 16 [10000/28539 (35%)]\tLoss: 0.837570\n",
      "Train Epoch: 16 [11000/28539 (39%)]\tLoss: 0.824821\n",
      "Train Epoch: 16 [12000/28539 (42%)]\tLoss: 0.740927\n",
      "Train Epoch: 16 [13000/28539 (46%)]\tLoss: 0.807397\n",
      "Train Epoch: 16 [14000/28539 (49%)]\tLoss: 0.684434\n",
      "Train Epoch: 16 [15000/28539 (53%)]\tLoss: 0.667865\n",
      "Train Epoch: 16 [16000/28539 (56%)]\tLoss: 0.811782\n",
      "Train Epoch: 16 [17000/28539 (60%)]\tLoss: 0.817893\n",
      "Train Epoch: 16 [18000/28539 (63%)]\tLoss: 0.748785\n",
      "Train Epoch: 16 [19000/28539 (67%)]\tLoss: 0.730290\n",
      "Train Epoch: 16 [20000/28539 (70%)]\tLoss: 0.947462\n",
      "Train Epoch: 16 [21000/28539 (74%)]\tLoss: 0.838926\n",
      "Train Epoch: 16 [22000/28539 (77%)]\tLoss: 0.881208\n",
      "Train Epoch: 16 [23000/28539 (81%)]\tLoss: 0.723377\n",
      "Train Epoch: 16 [24000/28539 (84%)]\tLoss: 0.712765\n",
      "Train Epoch: 16 [25000/28539 (88%)]\tLoss: 0.703555\n",
      "Train Epoch: 16 [26000/28539 (91%)]\tLoss: 0.768765\n",
      "Train Epoch: 16 [27000/28539 (95%)]\tLoss: 0.654173\n",
      "Train Epoch: 16 [28000/28539 (98%)]\tLoss: 0.779031\n",
      "Elapsed time 8.55 minutes\n",
      "Train Epoch: 17 lr = 0.00014284605771348484\n",
      "Train Epoch: 17 [0000/28539 (0%)]\tLoss: 0.552953\n",
      "Train Epoch: 17 [1000/28539 (4%)]\tLoss: 0.744343\n",
      "Train Epoch: 17 [2000/28539 (7%)]\tLoss: 0.659609\n",
      "Train Epoch: 17 [3000/28539 (11%)]\tLoss: 0.726811\n",
      "Train Epoch: 17 [4000/28539 (14%)]\tLoss: 0.761193\n",
      "Train Epoch: 17 [5000/28539 (18%)]\tLoss: 0.740458\n",
      "Train Epoch: 17 [6000/28539 (21%)]\tLoss: 0.806392\n",
      "Train Epoch: 17 [7000/28539 (25%)]\tLoss: 0.884046\n",
      "Train Epoch: 17 [8000/28539 (28%)]\tLoss: 0.662646\n",
      "Train Epoch: 17 [9000/28539 (32%)]\tLoss: 0.802011\n",
      "Train Epoch: 17 [10000/28539 (35%)]\tLoss: 1.132523\n",
      "Train Epoch: 17 [11000/28539 (39%)]\tLoss: 0.729743\n",
      "Train Epoch: 17 [12000/28539 (42%)]\tLoss: 0.877491\n",
      "Train Epoch: 17 [13000/28539 (46%)]\tLoss: 0.785566\n",
      "Train Epoch: 17 [14000/28539 (49%)]\tLoss: 0.987353\n",
      "Train Epoch: 17 [15000/28539 (53%)]\tLoss: 0.721471\n",
      "Train Epoch: 17 [16000/28539 (56%)]\tLoss: 0.767289\n",
      "Train Epoch: 17 [17000/28539 (60%)]\tLoss: 0.600939\n",
      "Train Epoch: 17 [18000/28539 (63%)]\tLoss: 0.716473\n",
      "Train Epoch: 17 [19000/28539 (67%)]\tLoss: 0.730813\n",
      "Train Epoch: 17 [20000/28539 (70%)]\tLoss: 0.657844\n",
      "Train Epoch: 17 [21000/28539 (74%)]\tLoss: 0.690701\n",
      "Train Epoch: 17 [22000/28539 (77%)]\tLoss: 0.773104\n",
      "Train Epoch: 17 [23000/28539 (81%)]\tLoss: 0.670620\n",
      "Train Epoch: 17 [24000/28539 (84%)]\tLoss: 0.666031\n",
      "Train Epoch: 17 [25000/28539 (88%)]\tLoss: 0.753675\n",
      "Train Epoch: 17 [26000/28539 (91%)]\tLoss: 0.710124\n",
      "Train Epoch: 17 [27000/28539 (95%)]\tLoss: 0.760992\n",
      "Train Epoch: 17 [28000/28539 (98%)]\tLoss: 0.724456\n",
      "Elapsed time 8.55 minutes\n",
      "Train Epoch: 18 lr = 0.000107131914856342\n",
      "Train Epoch: 18 [0000/28539 (0%)]\tLoss: 0.665439\n",
      "Train Epoch: 18 [1000/28539 (4%)]\tLoss: 0.879575\n",
      "Train Epoch: 18 [2000/28539 (7%)]\tLoss: 0.633158\n",
      "Train Epoch: 18 [3000/28539 (11%)]\tLoss: 0.711267\n",
      "Train Epoch: 18 [4000/28539 (14%)]\tLoss: 0.594115\n",
      "Train Epoch: 18 [5000/28539 (18%)]\tLoss: 0.611585\n",
      "Train Epoch: 18 [6000/28539 (21%)]\tLoss: 0.774905\n",
      "Train Epoch: 18 [7000/28539 (25%)]\tLoss: 0.835637\n",
      "Train Epoch: 18 [8000/28539 (28%)]\tLoss: 0.647466\n",
      "Train Epoch: 18 [9000/28539 (32%)]\tLoss: 0.721851\n",
      "Train Epoch: 18 [10000/28539 (35%)]\tLoss: 0.824754\n",
      "Train Epoch: 18 [11000/28539 (39%)]\tLoss: 0.705051\n",
      "Train Epoch: 18 [12000/28539 (42%)]\tLoss: 0.673976\n",
      "Train Epoch: 18 [13000/28539 (46%)]\tLoss: 0.724924\n",
      "Train Epoch: 18 [14000/28539 (49%)]\tLoss: 0.641483\n",
      "Train Epoch: 18 [15000/28539 (53%)]\tLoss: 0.891375\n",
      "Train Epoch: 18 [16000/28539 (56%)]\tLoss: 0.759851\n",
      "Train Epoch: 18 [17000/28539 (60%)]\tLoss: 0.681342\n",
      "Train Epoch: 18 [18000/28539 (63%)]\tLoss: 0.658104\n",
      "Train Epoch: 18 [19000/28539 (67%)]\tLoss: 0.624601\n",
      "Train Epoch: 18 [20000/28539 (70%)]\tLoss: 0.756932\n",
      "Train Epoch: 18 [21000/28539 (74%)]\tLoss: 0.756190\n",
      "Train Epoch: 18 [22000/28539 (77%)]\tLoss: 0.717723\n",
      "Train Epoch: 18 [23000/28539 (81%)]\tLoss: 0.730292\n",
      "Train Epoch: 18 [24000/28539 (84%)]\tLoss: 0.830348\n",
      "Train Epoch: 18 [25000/28539 (88%)]\tLoss: 0.686526\n",
      "Train Epoch: 18 [26000/28539 (91%)]\tLoss: 0.675590\n",
      "Train Epoch: 18 [27000/28539 (95%)]\tLoss: 0.775868\n",
      "Train Epoch: 18 [28000/28539 (98%)]\tLoss: 0.809170\n",
      "Elapsed time 8.55 minutes\n",
      "Train Epoch: 19 lr = 7.141777199919916e-05\n",
      "Train Epoch: 19 [0000/28539 (0%)]\tLoss: 0.685989\n",
      "Train Epoch: 19 [1000/28539 (4%)]\tLoss: 0.650744\n",
      "Train Epoch: 19 [2000/28539 (7%)]\tLoss: 0.829164\n",
      "Train Epoch: 19 [3000/28539 (11%)]\tLoss: 0.767240\n",
      "Train Epoch: 19 [4000/28539 (14%)]\tLoss: 0.678044\n",
      "Train Epoch: 19 [5000/28539 (18%)]\tLoss: 0.669507\n",
      "Train Epoch: 19 [6000/28539 (21%)]\tLoss: 0.710986\n",
      "Train Epoch: 19 [7000/28539 (25%)]\tLoss: 0.665048\n",
      "Train Epoch: 19 [8000/28539 (28%)]\tLoss: 0.624773\n",
      "Train Epoch: 19 [9000/28539 (32%)]\tLoss: 0.834004\n",
      "Train Epoch: 19 [10000/28539 (35%)]\tLoss: 0.842903\n",
      "Train Epoch: 19 [11000/28539 (39%)]\tLoss: 0.836112\n",
      "Train Epoch: 19 [12000/28539 (42%)]\tLoss: 0.777837\n",
      "Train Epoch: 19 [13000/28539 (46%)]\tLoss: 0.646684\n",
      "Train Epoch: 19 [14000/28539 (49%)]\tLoss: 0.731161\n",
      "Train Epoch: 19 [15000/28539 (53%)]\tLoss: 0.692356\n",
      "Train Epoch: 19 [16000/28539 (56%)]\tLoss: 0.750676\n",
      "Train Epoch: 19 [17000/28539 (60%)]\tLoss: 0.683512\n",
      "Train Epoch: 19 [18000/28539 (63%)]\tLoss: 0.580301\n",
      "Train Epoch: 19 [19000/28539 (67%)]\tLoss: 0.706550\n",
      "Train Epoch: 19 [20000/28539 (70%)]\tLoss: 0.717816\n",
      "Train Epoch: 19 [21000/28539 (74%)]\tLoss: 0.727667\n",
      "Train Epoch: 19 [22000/28539 (77%)]\tLoss: 0.773697\n",
      "Train Epoch: 19 [23000/28539 (81%)]\tLoss: 0.868535\n",
      "Train Epoch: 19 [24000/28539 (84%)]\tLoss: 0.585200\n",
      "Train Epoch: 19 [25000/28539 (88%)]\tLoss: 0.602467\n",
      "Train Epoch: 19 [26000/28539 (91%)]\tLoss: 0.640138\n",
      "Train Epoch: 19 [27000/28539 (95%)]\tLoss: 0.644181\n",
      "Train Epoch: 19 [28000/28539 (98%)]\tLoss: 0.668354\n",
      "Elapsed time 8.55 minutes\n",
      "Train Epoch: 20 lr = 3.570362914205626e-05\n",
      "Train Epoch: 20 [0000/28539 (0%)]\tLoss: 0.862588\n",
      "Train Epoch: 20 [1000/28539 (4%)]\tLoss: 0.907151\n",
      "Train Epoch: 20 [2000/28539 (7%)]\tLoss: 0.848090\n",
      "Train Epoch: 20 [3000/28539 (11%)]\tLoss: 0.618533\n",
      "Train Epoch: 20 [4000/28539 (14%)]\tLoss: 0.750837\n",
      "Train Epoch: 20 [5000/28539 (18%)]\tLoss: 0.780303\n",
      "Train Epoch: 20 [6000/28539 (21%)]\tLoss: 0.727522\n",
      "Train Epoch: 20 [7000/28539 (25%)]\tLoss: 0.795030\n",
      "Train Epoch: 20 [8000/28539 (28%)]\tLoss: 0.608223\n",
      "Train Epoch: 20 [9000/28539 (32%)]\tLoss: 0.672771\n",
      "Train Epoch: 20 [10000/28539 (35%)]\tLoss: 0.579987\n",
      "Train Epoch: 20 [11000/28539 (39%)]\tLoss: 0.783784\n",
      "Train Epoch: 20 [12000/28539 (42%)]\tLoss: 0.577202\n",
      "Train Epoch: 20 [13000/28539 (46%)]\tLoss: 0.700888\n",
      "Train Epoch: 20 [14000/28539 (49%)]\tLoss: 0.555176\n",
      "Train Epoch: 20 [15000/28539 (53%)]\tLoss: 0.878097\n",
      "Train Epoch: 20 [16000/28539 (56%)]\tLoss: 0.803941\n",
      "Train Epoch: 20 [17000/28539 (60%)]\tLoss: 0.762768\n",
      "Train Epoch: 20 [18000/28539 (63%)]\tLoss: 0.652675\n",
      "Train Epoch: 20 [19000/28539 (67%)]\tLoss: 0.768493\n",
      "Train Epoch: 20 [20000/28539 (70%)]\tLoss: 0.808199\n",
      "Train Epoch: 20 [21000/28539 (74%)]\tLoss: 0.691579\n",
      "Train Epoch: 20 [22000/28539 (77%)]\tLoss: 0.677512\n",
      "Train Epoch: 20 [23000/28539 (81%)]\tLoss: 0.798641\n",
      "Train Epoch: 20 [24000/28539 (84%)]\tLoss: 0.660967\n",
      "Train Epoch: 20 [25000/28539 (88%)]\tLoss: 0.781697\n",
      "Train Epoch: 20 [26000/28539 (91%)]\tLoss: 0.571266\n",
      "Train Epoch: 20 [27000/28539 (95%)]\tLoss: 0.721669\n",
      "Train Epoch: 20 [28000/28539 (98%)]\tLoss: 0.598117\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Test set: Average loss: 0.6145, Average CER: 0.185958 Average WER: 0.5542\n",
      "\n",
      "\n",
      "EXAMPLE\n",
      "GT:\n",
      "i love thee with a love i seemed to lose with my lost saints i love thee with the breath smiles tears of all my life and if god choose i shall but love thee better after death\n",
      "\n",
      "Network output:\n",
      "i leve the with a love i seemed to loe with mi lost sains i love the with the breaath smalesear of al myalife and if gad cshes i shall but love the better after daath\n",
      "Elapsed time 14.89 minutes\n",
      "Num Model Parameters 9506269\n",
      "Train Epoch: 1 lr = 2e-05\n",
      "Train Epoch: 1 [0000/28539 (0%)]\tLoss: 6.384459\n",
      "Train Epoch: 1 [1000/28539 (4%)]\tLoss: 2.983166\n",
      "Train Epoch: 1 [2000/28539 (7%)]\tLoss: 2.877962\n",
      "Train Epoch: 1 [3000/28539 (11%)]\tLoss: 2.897725\n",
      "Train Epoch: 1 [4000/28539 (14%)]\tLoss: 2.872590\n",
      "Train Epoch: 1 [5000/28539 (18%)]\tLoss: 2.865914\n",
      "Train Epoch: 1 [6000/28539 (21%)]\tLoss: 2.849029\n",
      "Train Epoch: 1 [7000/28539 (25%)]\tLoss: 2.856933\n",
      "Train Epoch: 1 [8000/28539 (28%)]\tLoss: 2.856792\n",
      "Train Epoch: 1 [9000/28539 (32%)]\tLoss: 2.859665\n",
      "Train Epoch: 1 [10000/28539 (35%)]\tLoss: 2.828984\n",
      "Train Epoch: 1 [11000/28539 (39%)]\tLoss: 2.783277\n",
      "Train Epoch: 1 [12000/28539 (42%)]\tLoss: 2.735206\n",
      "Train Epoch: 1 [13000/28539 (46%)]\tLoss: 2.611950\n",
      "Train Epoch: 1 [14000/28539 (49%)]\tLoss: 2.537990\n",
      "Train Epoch: 1 [15000/28539 (53%)]\tLoss: 2.399949\n",
      "Train Epoch: 1 [16000/28539 (56%)]\tLoss: 2.278059\n",
      "Train Epoch: 1 [17000/28539 (60%)]\tLoss: 2.152602\n",
      "Train Epoch: 1 [18000/28539 (63%)]\tLoss: 2.207181\n",
      "Train Epoch: 1 [19000/28539 (67%)]\tLoss: 1.996338\n",
      "Train Epoch: 1 [20000/28539 (70%)]\tLoss: 1.995719\n",
      "Train Epoch: 1 [21000/28539 (74%)]\tLoss: 1.944386\n",
      "Train Epoch: 1 [22000/28539 (77%)]\tLoss: 1.944255\n",
      "Train Epoch: 1 [23000/28539 (81%)]\tLoss: 1.930427\n",
      "Train Epoch: 1 [24000/28539 (84%)]\tLoss: 1.981368\n",
      "Train Epoch: 1 [25000/28539 (88%)]\tLoss: 1.966149\n",
      "Train Epoch: 1 [26000/28539 (91%)]\tLoss: 1.843747\n",
      "Train Epoch: 1 [27000/28539 (95%)]\tLoss: 1.783533\n",
      "Train Epoch: 1 [28000/28539 (98%)]\tLoss: 1.698639\n",
      "Elapsed time 11.51 minutes\n",
      "Train Epoch: 2 lr = 0.00010000467207849092\n",
      "Train Epoch: 2 [0000/28539 (0%)]\tLoss: 1.767156\n",
      "Train Epoch: 2 [1000/28539 (4%)]\tLoss: 1.655516\n",
      "Train Epoch: 2 [2000/28539 (7%)]\tLoss: 1.776938\n",
      "Train Epoch: 2 [3000/28539 (11%)]\tLoss: 1.580265\n",
      "Train Epoch: 2 [4000/28539 (14%)]\tLoss: 1.858287\n",
      "Train Epoch: 2 [5000/28539 (18%)]\tLoss: 1.598438\n",
      "Train Epoch: 2 [6000/28539 (21%)]\tLoss: 1.628563\n",
      "Train Epoch: 2 [7000/28539 (25%)]\tLoss: 1.833380\n",
      "Train Epoch: 2 [8000/28539 (28%)]\tLoss: 1.749227\n",
      "Train Epoch: 2 [9000/28539 (32%)]\tLoss: 1.632911\n",
      "Train Epoch: 2 [10000/28539 (35%)]\tLoss: 1.595269\n",
      "Train Epoch: 2 [11000/28539 (39%)]\tLoss: 1.579521\n",
      "Train Epoch: 2 [12000/28539 (42%)]\tLoss: 1.722716\n",
      "Train Epoch: 2 [13000/28539 (46%)]\tLoss: 1.643753\n",
      "Train Epoch: 2 [14000/28539 (49%)]\tLoss: 1.593984\n",
      "Train Epoch: 2 [15000/28539 (53%)]\tLoss: 1.680602\n",
      "Train Epoch: 2 [16000/28539 (56%)]\tLoss: 1.454922\n",
      "Train Epoch: 2 [17000/28539 (60%)]\tLoss: 1.616414\n",
      "Train Epoch: 2 [18000/28539 (63%)]\tLoss: 1.468131\n",
      "Train Epoch: 2 [19000/28539 (67%)]\tLoss: 1.339689\n",
      "Train Epoch: 2 [20000/28539 (70%)]\tLoss: 1.660769\n",
      "Train Epoch: 2 [21000/28539 (74%)]\tLoss: 1.521141\n",
      "Train Epoch: 2 [22000/28539 (77%)]\tLoss: 1.400745\n",
      "Train Epoch: 2 [23000/28539 (81%)]\tLoss: 1.428025\n",
      "Train Epoch: 2 [24000/28539 (84%)]\tLoss: 1.446809\n",
      "Train Epoch: 2 [25000/28539 (88%)]\tLoss: 1.474189\n",
      "Train Epoch: 2 [26000/28539 (91%)]\tLoss: 1.453212\n",
      "Train Epoch: 2 [27000/28539 (95%)]\tLoss: 1.500805\n",
      "Train Epoch: 2 [28000/28539 (98%)]\tLoss: 1.407078\n",
      "Elapsed time 11.50 minutes\n",
      "Train Epoch: 3 lr = 0.00018000934415698185\n",
      "Train Epoch: 3 [0000/28539 (0%)]\tLoss: 1.386075\n",
      "Train Epoch: 3 [1000/28539 (4%)]\tLoss: 1.381760\n",
      "Train Epoch: 3 [2000/28539 (7%)]\tLoss: 1.429041\n",
      "Train Epoch: 3 [3000/28539 (11%)]\tLoss: 1.353431\n",
      "Train Epoch: 3 [4000/28539 (14%)]\tLoss: 1.417325\n",
      "Train Epoch: 3 [5000/28539 (18%)]\tLoss: 1.249094\n",
      "Train Epoch: 3 [6000/28539 (21%)]\tLoss: 1.396129\n",
      "Train Epoch: 3 [7000/28539 (25%)]\tLoss: 1.366206\n",
      "Train Epoch: 3 [8000/28539 (28%)]\tLoss: 1.320451\n",
      "Train Epoch: 3 [9000/28539 (32%)]\tLoss: 1.263060\n",
      "Train Epoch: 3 [10000/28539 (35%)]\tLoss: 1.200606\n",
      "Train Epoch: 3 [11000/28539 (39%)]\tLoss: 1.309972\n",
      "Train Epoch: 3 [12000/28539 (42%)]\tLoss: 1.371690\n",
      "Train Epoch: 3 [13000/28539 (46%)]\tLoss: 1.212376\n",
      "Train Epoch: 3 [14000/28539 (49%)]\tLoss: 1.458749\n",
      "Train Epoch: 3 [15000/28539 (53%)]\tLoss: 1.203388\n",
      "Train Epoch: 3 [16000/28539 (56%)]\tLoss: 1.366141\n",
      "Train Epoch: 3 [17000/28539 (60%)]\tLoss: 1.381453\n",
      "Train Epoch: 3 [18000/28539 (63%)]\tLoss: 1.237505\n",
      "Train Epoch: 3 [19000/28539 (67%)]\tLoss: 1.276179\n",
      "Train Epoch: 3 [20000/28539 (70%)]\tLoss: 1.242286\n",
      "Train Epoch: 3 [21000/28539 (74%)]\tLoss: 1.271719\n",
      "Train Epoch: 3 [22000/28539 (77%)]\tLoss: 1.167949\n",
      "Train Epoch: 3 [23000/28539 (81%)]\tLoss: 1.026688\n",
      "Train Epoch: 3 [24000/28539 (84%)]\tLoss: 1.234395\n",
      "Train Epoch: 3 [25000/28539 (88%)]\tLoss: 1.257075\n",
      "Train Epoch: 3 [26000/28539 (91%)]\tLoss: 1.099388\n",
      "Train Epoch: 3 [27000/28539 (95%)]\tLoss: 1.364432\n",
      "Train Epoch: 3 [28000/28539 (98%)]\tLoss: 1.262353\n",
      "Elapsed time 11.50 minutes\n",
      "Train Epoch: 4 lr = 0.00026001401623547275\n",
      "Train Epoch: 4 [0000/28539 (0%)]\tLoss: 1.065818\n",
      "Train Epoch: 4 [1000/28539 (4%)]\tLoss: 1.142993\n",
      "Train Epoch: 4 [2000/28539 (7%)]\tLoss: 1.036431\n",
      "Train Epoch: 4 [3000/28539 (11%)]\tLoss: 1.222041\n",
      "Train Epoch: 4 [4000/28539 (14%)]\tLoss: 1.103993\n",
      "Train Epoch: 4 [5000/28539 (18%)]\tLoss: 1.215253\n",
      "Train Epoch: 4 [6000/28539 (21%)]\tLoss: 1.136067\n",
      "Train Epoch: 4 [7000/28539 (25%)]\tLoss: 1.158105\n",
      "Train Epoch: 4 [8000/28539 (28%)]\tLoss: 1.064791\n",
      "Train Epoch: 4 [9000/28539 (32%)]\tLoss: 1.008553\n",
      "Train Epoch: 4 [10000/28539 (35%)]\tLoss: 1.136112\n",
      "Train Epoch: 4 [11000/28539 (39%)]\tLoss: 1.097610\n",
      "Train Epoch: 4 [12000/28539 (42%)]\tLoss: 1.078152\n",
      "Train Epoch: 4 [13000/28539 (46%)]\tLoss: 1.177681\n",
      "Train Epoch: 4 [14000/28539 (49%)]\tLoss: 1.186281\n",
      "Train Epoch: 4 [15000/28539 (53%)]\tLoss: 1.337325\n",
      "Train Epoch: 4 [16000/28539 (56%)]\tLoss: 1.110213\n",
      "Train Epoch: 4 [17000/28539 (60%)]\tLoss: 1.058022\n",
      "Train Epoch: 4 [18000/28539 (63%)]\tLoss: 1.111275\n",
      "Train Epoch: 4 [19000/28539 (67%)]\tLoss: 1.272029\n",
      "Train Epoch: 4 [20000/28539 (70%)]\tLoss: 1.037357\n",
      "Train Epoch: 4 [21000/28539 (74%)]\tLoss: 1.074492\n",
      "Train Epoch: 4 [22000/28539 (77%)]\tLoss: 0.958168\n",
      "Train Epoch: 4 [23000/28539 (81%)]\tLoss: 1.048519\n",
      "Train Epoch: 4 [24000/28539 (84%)]\tLoss: 1.022636\n",
      "Train Epoch: 4 [25000/28539 (88%)]\tLoss: 1.086976\n",
      "Train Epoch: 4 [26000/28539 (91%)]\tLoss: 1.093358\n",
      "Train Epoch: 4 [27000/28539 (95%)]\tLoss: 1.158615\n",
      "Train Epoch: 4 [28000/28539 (98%)]\tLoss: 0.953609\n",
      "Elapsed time 11.51 minutes\n",
      "Train Epoch: 5 lr = 0.0003400186883139637\n",
      "Train Epoch: 5 [0000/28539 (0%)]\tLoss: 0.956632\n",
      "Train Epoch: 5 [1000/28539 (4%)]\tLoss: 1.119614\n",
      "Train Epoch: 5 [2000/28539 (7%)]\tLoss: 0.918099\n",
      "Train Epoch: 5 [3000/28539 (11%)]\tLoss: 1.207398\n",
      "Train Epoch: 5 [4000/28539 (14%)]\tLoss: 1.001603\n",
      "Train Epoch: 5 [5000/28539 (18%)]\tLoss: 1.064560\n",
      "Train Epoch: 5 [6000/28539 (21%)]\tLoss: 1.051625\n",
      "Train Epoch: 5 [7000/28539 (25%)]\tLoss: 1.039344\n",
      "Train Epoch: 5 [8000/28539 (28%)]\tLoss: 1.029450\n",
      "Train Epoch: 5 [9000/28539 (32%)]\tLoss: 1.031847\n",
      "Train Epoch: 5 [10000/28539 (35%)]\tLoss: 1.278172\n",
      "Train Epoch: 5 [11000/28539 (39%)]\tLoss: 1.023002\n",
      "Train Epoch: 5 [12000/28539 (42%)]\tLoss: 1.177205\n",
      "Train Epoch: 5 [13000/28539 (46%)]\tLoss: 1.059085\n",
      "Train Epoch: 5 [14000/28539 (49%)]\tLoss: 0.951551\n",
      "Train Epoch: 5 [15000/28539 (53%)]\tLoss: 1.003510\n",
      "Train Epoch: 5 [16000/28539 (56%)]\tLoss: 1.079205\n",
      "Train Epoch: 5 [17000/28539 (60%)]\tLoss: 1.078779\n",
      "Train Epoch: 5 [18000/28539 (63%)]\tLoss: 1.078474\n",
      "Train Epoch: 5 [19000/28539 (67%)]\tLoss: 1.031279\n",
      "Train Epoch: 5 [20000/28539 (70%)]\tLoss: 1.027861\n",
      "Train Epoch: 5 [21000/28539 (74%)]\tLoss: 1.116637\n",
      "Train Epoch: 5 [22000/28539 (77%)]\tLoss: 0.822277\n",
      "Train Epoch: 5 [23000/28539 (81%)]\tLoss: 1.085599\n",
      "Train Epoch: 5 [24000/28539 (84%)]\tLoss: 1.043030\n",
      "Train Epoch: 5 [25000/28539 (88%)]\tLoss: 1.018479\n",
      "Train Epoch: 5 [26000/28539 (91%)]\tLoss: 0.967221\n",
      "Train Epoch: 5 [27000/28539 (95%)]\tLoss: 0.948761\n",
      "Train Epoch: 5 [28000/28539 (98%)]\tLoss: 1.039940\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Test set: Average loss: 0.7679, Average CER: 0.238382 Average WER: 0.6508\n",
      "\n",
      "\n",
      "EXAMPLE\n",
      "GT:\n",
      "i love thee with a love i seemed to lose with my lost saints i love thee with the breath smiles tears of all my life and if god choose i shall but love thee better after death\n",
      "\n",
      "Network output:\n",
      "i leve the with alove i sened to be with my lost sas i love be with the breat smils t hears of ahl mialin and if gan ches i show but love the better after deat\n",
      "Elapsed time 17.77 minutes\n",
      "Train Epoch: 6 lr = 0.0004200233603924546\n",
      "Train Epoch: 6 [0000/28539 (0%)]\tLoss: 1.002420\n",
      "Train Epoch: 6 [1000/28539 (4%)]\tLoss: 0.899006\n",
      "Train Epoch: 6 [2000/28539 (7%)]\tLoss: 0.938320\n",
      "Train Epoch: 6 [3000/28539 (11%)]\tLoss: 0.918642\n",
      "Train Epoch: 6 [4000/28539 (14%)]\tLoss: 0.937687\n",
      "Train Epoch: 6 [5000/28539 (18%)]\tLoss: 0.941673\n",
      "Train Epoch: 6 [6000/28539 (21%)]\tLoss: 1.065674\n",
      "Train Epoch: 6 [7000/28539 (25%)]\tLoss: 1.021230\n",
      "Train Epoch: 6 [8000/28539 (28%)]\tLoss: 0.962448\n",
      "Train Epoch: 6 [9000/28539 (32%)]\tLoss: 0.939314\n",
      "Train Epoch: 6 [10000/28539 (35%)]\tLoss: 0.979026\n",
      "Train Epoch: 6 [11000/28539 (39%)]\tLoss: 0.920065\n",
      "Train Epoch: 6 [12000/28539 (42%)]\tLoss: 1.046684\n",
      "Train Epoch: 6 [13000/28539 (46%)]\tLoss: 0.992267\n",
      "Train Epoch: 6 [14000/28539 (49%)]\tLoss: 0.880129\n",
      "Train Epoch: 6 [15000/28539 (53%)]\tLoss: 0.991630\n",
      "Train Epoch: 6 [16000/28539 (56%)]\tLoss: 0.885782\n",
      "Train Epoch: 6 [17000/28539 (60%)]\tLoss: 1.023302\n",
      "Train Epoch: 6 [18000/28539 (63%)]\tLoss: 0.781813\n",
      "Train Epoch: 6 [19000/28539 (67%)]\tLoss: 0.878950\n",
      "Train Epoch: 6 [20000/28539 (70%)]\tLoss: 0.910803\n",
      "Train Epoch: 6 [21000/28539 (74%)]\tLoss: 1.149617\n",
      "Train Epoch: 6 [22000/28539 (77%)]\tLoss: 0.867973\n",
      "Train Epoch: 6 [23000/28539 (81%)]\tLoss: 0.988498\n",
      "Train Epoch: 6 [24000/28539 (84%)]\tLoss: 1.004461\n",
      "Train Epoch: 6 [25000/28539 (88%)]\tLoss: 0.927518\n",
      "Train Epoch: 6 [26000/28539 (91%)]\tLoss: 0.973937\n",
      "Train Epoch: 6 [27000/28539 (95%)]\tLoss: 1.021068\n",
      "Train Epoch: 6 [28000/28539 (98%)]\tLoss: 0.902595\n",
      "Elapsed time 11.51 minutes\n",
      "Train Epoch: 7 lr = 0.0004999874862849134\n",
      "Train Epoch: 7 [0000/28539 (0%)]\tLoss: 0.752196\n",
      "Train Epoch: 7 [1000/28539 (4%)]\tLoss: 0.757631\n",
      "Train Epoch: 7 [2000/28539 (7%)]\tLoss: 1.009740\n",
      "Train Epoch: 7 [3000/28539 (11%)]\tLoss: 0.888324\n",
      "Train Epoch: 7 [4000/28539 (14%)]\tLoss: 0.976265\n",
      "Train Epoch: 7 [5000/28539 (18%)]\tLoss: 0.798887\n",
      "Train Epoch: 7 [6000/28539 (21%)]\tLoss: 1.093884\n",
      "Train Epoch: 7 [7000/28539 (25%)]\tLoss: 0.795400\n",
      "Train Epoch: 7 [8000/28539 (28%)]\tLoss: 0.956457\n",
      "Train Epoch: 7 [9000/28539 (32%)]\tLoss: 0.911140\n",
      "Train Epoch: 7 [10000/28539 (35%)]\tLoss: 0.984610\n",
      "Train Epoch: 7 [11000/28539 (39%)]\tLoss: 0.856217\n",
      "Train Epoch: 7 [12000/28539 (42%)]\tLoss: 0.805185\n",
      "Train Epoch: 7 [13000/28539 (46%)]\tLoss: 0.885486\n",
      "Train Epoch: 7 [14000/28539 (49%)]\tLoss: 0.818432\n",
      "Train Epoch: 7 [15000/28539 (53%)]\tLoss: 0.978522\n",
      "Train Epoch: 7 [16000/28539 (56%)]\tLoss: 0.829737\n",
      "Train Epoch: 7 [17000/28539 (60%)]\tLoss: 0.864064\n",
      "Train Epoch: 7 [18000/28539 (63%)]\tLoss: 0.984488\n",
      "Train Epoch: 7 [19000/28539 (67%)]\tLoss: 1.012607\n",
      "Train Epoch: 7 [20000/28539 (70%)]\tLoss: 0.989449\n",
      "Train Epoch: 7 [21000/28539 (74%)]\tLoss: 0.831616\n",
      "Train Epoch: 7 [22000/28539 (77%)]\tLoss: 0.879360\n",
      "Train Epoch: 7 [23000/28539 (81%)]\tLoss: 0.865071\n",
      "Train Epoch: 7 [24000/28539 (84%)]\tLoss: 0.997461\n",
      "Train Epoch: 7 [25000/28539 (88%)]\tLoss: 0.848930\n",
      "Train Epoch: 7 [26000/28539 (91%)]\tLoss: 0.835282\n",
      "Train Epoch: 7 [27000/28539 (95%)]\tLoss: 0.854811\n",
      "Train Epoch: 7 [28000/28539 (98%)]\tLoss: 0.948664\n",
      "Elapsed time 11.53 minutes\n",
      "Train Epoch: 8 lr = 0.00046427334342777056\n",
      "Train Epoch: 8 [0000/28539 (0%)]\tLoss: 0.826831\n",
      "Train Epoch: 8 [1000/28539 (4%)]\tLoss: 0.736946\n",
      "Train Epoch: 8 [2000/28539 (7%)]\tLoss: 0.934112\n",
      "Train Epoch: 8 [3000/28539 (11%)]\tLoss: 0.737354\n",
      "Train Epoch: 8 [4000/28539 (14%)]\tLoss: 0.961104\n",
      "Train Epoch: 8 [5000/28539 (18%)]\tLoss: 0.881905\n",
      "Train Epoch: 8 [6000/28539 (21%)]\tLoss: 0.738200\n",
      "Train Epoch: 8 [7000/28539 (25%)]\tLoss: 0.828188\n",
      "Train Epoch: 8 [8000/28539 (28%)]\tLoss: 0.740624\n",
      "Train Epoch: 8 [9000/28539 (32%)]\tLoss: 0.795304\n",
      "Train Epoch: 8 [10000/28539 (35%)]\tLoss: 0.882578\n",
      "Train Epoch: 8 [11000/28539 (39%)]\tLoss: 0.778260\n",
      "Train Epoch: 8 [12000/28539 (42%)]\tLoss: 0.750746\n",
      "Train Epoch: 8 [13000/28539 (46%)]\tLoss: 0.676601\n",
      "Train Epoch: 8 [14000/28539 (49%)]\tLoss: 0.831928\n",
      "Train Epoch: 8 [15000/28539 (53%)]\tLoss: 0.854128\n",
      "Train Epoch: 8 [16000/28539 (56%)]\tLoss: 0.770712\n",
      "Train Epoch: 8 [17000/28539 (60%)]\tLoss: 0.676074\n",
      "Train Epoch: 8 [18000/28539 (63%)]\tLoss: 0.695067\n",
      "Train Epoch: 8 [19000/28539 (67%)]\tLoss: 0.965468\n",
      "Train Epoch: 8 [20000/28539 (70%)]\tLoss: 0.886597\n",
      "Train Epoch: 8 [21000/28539 (74%)]\tLoss: 0.816065\n",
      "Train Epoch: 8 [22000/28539 (77%)]\tLoss: 0.753185\n",
      "Train Epoch: 8 [23000/28539 (81%)]\tLoss: 0.643090\n",
      "Train Epoch: 8 [24000/28539 (84%)]\tLoss: 0.858877\n",
      "Train Epoch: 8 [25000/28539 (88%)]\tLoss: 0.926135\n",
      "Train Epoch: 8 [26000/28539 (91%)]\tLoss: 0.930710\n",
      "Train Epoch: 8 [27000/28539 (95%)]\tLoss: 0.725807\n",
      "Train Epoch: 8 [28000/28539 (98%)]\tLoss: 0.955454\n",
      "Elapsed time 11.51 minutes\n",
      "Train Epoch: 9 lr = 0.0004285592005706277\n",
      "Train Epoch: 9 [0000/28539 (0%)]\tLoss: 0.795667\n",
      "Train Epoch: 9 [1000/28539 (4%)]\tLoss: 0.853828\n",
      "Train Epoch: 9 [2000/28539 (7%)]\tLoss: 0.796863\n",
      "Train Epoch: 9 [3000/28539 (11%)]\tLoss: 0.709217\n",
      "Train Epoch: 9 [4000/28539 (14%)]\tLoss: 0.929459\n",
      "Train Epoch: 9 [5000/28539 (18%)]\tLoss: 0.727929\n",
      "Train Epoch: 9 [6000/28539 (21%)]\tLoss: 0.775159\n",
      "Train Epoch: 9 [7000/28539 (25%)]\tLoss: 0.805857\n",
      "Train Epoch: 9 [8000/28539 (28%)]\tLoss: 0.942237\n",
      "Train Epoch: 9 [9000/28539 (32%)]\tLoss: 0.864681\n",
      "Train Epoch: 9 [10000/28539 (35%)]\tLoss: 0.814903\n",
      "Train Epoch: 9 [11000/28539 (39%)]\tLoss: 0.936965\n",
      "Train Epoch: 9 [12000/28539 (42%)]\tLoss: 0.831933\n",
      "Train Epoch: 9 [13000/28539 (46%)]\tLoss: 0.743347\n",
      "Train Epoch: 9 [14000/28539 (49%)]\tLoss: 0.880931\n",
      "Train Epoch: 9 [15000/28539 (53%)]\tLoss: 0.717142\n",
      "Train Epoch: 9 [16000/28539 (56%)]\tLoss: 0.792618\n",
      "Train Epoch: 9 [17000/28539 (60%)]\tLoss: 0.766364\n",
      "Train Epoch: 9 [18000/28539 (63%)]\tLoss: 0.819359\n",
      "Train Epoch: 9 [19000/28539 (67%)]\tLoss: 0.665714\n",
      "Train Epoch: 9 [20000/28539 (70%)]\tLoss: 0.719678\n",
      "Train Epoch: 9 [21000/28539 (74%)]\tLoss: 0.773518\n",
      "Train Epoch: 9 [22000/28539 (77%)]\tLoss: 0.731935\n",
      "Train Epoch: 9 [23000/28539 (81%)]\tLoss: 0.636683\n",
      "Train Epoch: 9 [24000/28539 (84%)]\tLoss: 0.854931\n",
      "Train Epoch: 9 [25000/28539 (88%)]\tLoss: 0.730163\n",
      "Train Epoch: 9 [26000/28539 (91%)]\tLoss: 0.711285\n",
      "Train Epoch: 9 [27000/28539 (95%)]\tLoss: 0.747243\n",
      "Train Epoch: 9 [28000/28539 (98%)]\tLoss: 1.004021\n",
      "Elapsed time 11.52 minutes\n",
      "Train Epoch: 10 lr = 0.0003928450577134848\n",
      "Train Epoch: 10 [0000/28539 (0%)]\tLoss: 0.711015\n",
      "Train Epoch: 10 [1000/28539 (4%)]\tLoss: 0.590699\n",
      "Train Epoch: 10 [2000/28539 (7%)]\tLoss: 0.744068\n",
      "Train Epoch: 10 [3000/28539 (11%)]\tLoss: 0.722311\n",
      "Train Epoch: 10 [4000/28539 (14%)]\tLoss: 0.774024\n",
      "Train Epoch: 10 [5000/28539 (18%)]\tLoss: 0.631489\n",
      "Train Epoch: 10 [6000/28539 (21%)]\tLoss: 0.626941\n",
      "Train Epoch: 10 [7000/28539 (25%)]\tLoss: 0.680531\n",
      "Train Epoch: 10 [8000/28539 (28%)]\tLoss: 0.653557\n",
      "Train Epoch: 10 [9000/28539 (32%)]\tLoss: 0.731943\n",
      "Train Epoch: 10 [10000/28539 (35%)]\tLoss: 0.651106\n",
      "Train Epoch: 10 [11000/28539 (39%)]\tLoss: 0.678455\n",
      "Train Epoch: 10 [12000/28539 (42%)]\tLoss: 0.796855\n",
      "Train Epoch: 10 [13000/28539 (46%)]\tLoss: 0.660350\n",
      "Train Epoch: 10 [14000/28539 (49%)]\tLoss: 0.695593\n",
      "Train Epoch: 10 [15000/28539 (53%)]\tLoss: 1.127113\n",
      "Train Epoch: 10 [16000/28539 (56%)]\tLoss: 0.667755\n",
      "Train Epoch: 10 [17000/28539 (60%)]\tLoss: 0.692741\n",
      "Train Epoch: 10 [18000/28539 (63%)]\tLoss: 0.932717\n",
      "Train Epoch: 10 [19000/28539 (67%)]\tLoss: 0.679728\n",
      "Train Epoch: 10 [20000/28539 (70%)]\tLoss: 0.767799\n",
      "Train Epoch: 10 [21000/28539 (74%)]\tLoss: 0.672096\n",
      "Train Epoch: 10 [22000/28539 (77%)]\tLoss: 0.743429\n",
      "Train Epoch: 10 [23000/28539 (81%)]\tLoss: 0.781982\n",
      "Train Epoch: 10 [24000/28539 (84%)]\tLoss: 0.902107\n",
      "Train Epoch: 10 [25000/28539 (88%)]\tLoss: 0.623982\n",
      "Train Epoch: 10 [26000/28539 (91%)]\tLoss: 0.984368\n",
      "Train Epoch: 10 [27000/28539 (95%)]\tLoss: 0.782948\n",
      "Train Epoch: 10 [28000/28539 (98%)]\tLoss: 0.786270\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Test set: Average loss: 0.5592, Average CER: 0.170114 Average WER: 0.5013\n",
      "\n",
      "\n",
      "EXAMPLE\n",
      "GT:\n",
      "i love thee with a love i seemed to lose with my lost saints i love thee with the breath smiles tears of all my life and if god choose i shall but love thee better after death\n",
      "\n",
      "Network output:\n",
      "i love the with aloe i seemed to lo with my lost sans i love te with the breath smiles thers of alh my life and if god ches i shalwl but love the better after death\n",
      "Elapsed time 17.92 minutes\n",
      "Train Epoch: 11 lr = 0.000357130914856342\n",
      "Train Epoch: 11 [0000/28539 (0%)]\tLoss: 0.592083\n",
      "Train Epoch: 11 [1000/28539 (4%)]\tLoss: 0.712003\n",
      "Train Epoch: 11 [2000/28539 (7%)]\tLoss: 0.690656\n",
      "Train Epoch: 11 [3000/28539 (11%)]\tLoss: 0.806248\n",
      "Train Epoch: 11 [4000/28539 (14%)]\tLoss: 0.560956\n",
      "Train Epoch: 11 [5000/28539 (18%)]\tLoss: 0.717176\n",
      "Train Epoch: 11 [6000/28539 (21%)]\tLoss: 0.757117\n",
      "Train Epoch: 11 [7000/28539 (25%)]\tLoss: 0.688529\n",
      "Train Epoch: 11 [8000/28539 (28%)]\tLoss: 0.765599\n",
      "Train Epoch: 11 [9000/28539 (32%)]\tLoss: 0.619231\n",
      "Train Epoch: 11 [10000/28539 (35%)]\tLoss: 0.761763\n",
      "Train Epoch: 11 [11000/28539 (39%)]\tLoss: 0.592608\n",
      "Train Epoch: 11 [12000/28539 (42%)]\tLoss: 0.816287\n",
      "Train Epoch: 11 [13000/28539 (46%)]\tLoss: 0.723089\n",
      "Train Epoch: 11 [14000/28539 (49%)]\tLoss: 0.645676\n",
      "Train Epoch: 11 [15000/28539 (53%)]\tLoss: 0.645840\n",
      "Train Epoch: 11 [16000/28539 (56%)]\tLoss: 0.661004\n",
      "Train Epoch: 11 [17000/28539 (60%)]\tLoss: 0.639111\n",
      "Train Epoch: 11 [18000/28539 (63%)]\tLoss: 0.729268\n",
      "Train Epoch: 11 [19000/28539 (67%)]\tLoss: 0.905124\n",
      "Train Epoch: 11 [20000/28539 (70%)]\tLoss: 0.736676\n",
      "Train Epoch: 11 [21000/28539 (74%)]\tLoss: 0.761372\n",
      "Train Epoch: 11 [22000/28539 (77%)]\tLoss: 0.658962\n",
      "Train Epoch: 11 [23000/28539 (81%)]\tLoss: 0.718255\n",
      "Train Epoch: 11 [24000/28539 (84%)]\tLoss: 0.742412\n",
      "Train Epoch: 11 [25000/28539 (88%)]\tLoss: 0.685468\n",
      "Train Epoch: 11 [26000/28539 (91%)]\tLoss: 0.724179\n",
      "Train Epoch: 11 [27000/28539 (95%)]\tLoss: 0.625580\n",
      "Train Epoch: 11 [28000/28539 (98%)]\tLoss: 0.686695\n",
      "Elapsed time 11.51 minutes\n",
      "Train Epoch: 12 lr = 0.0003214167719991991\n",
      "Train Epoch: 12 [0000/28539 (0%)]\tLoss: 0.589382\n",
      "Train Epoch: 12 [1000/28539 (4%)]\tLoss: 0.619988\n",
      "Train Epoch: 12 [2000/28539 (7%)]\tLoss: 0.478441\n",
      "Train Epoch: 12 [3000/28539 (11%)]\tLoss: 0.744427\n",
      "Train Epoch: 12 [4000/28539 (14%)]\tLoss: 0.738886\n",
      "Train Epoch: 12 [5000/28539 (18%)]\tLoss: 0.639576\n",
      "Train Epoch: 12 [6000/28539 (21%)]\tLoss: 0.580770\n",
      "Train Epoch: 12 [7000/28539 (25%)]\tLoss: 0.530911\n",
      "Train Epoch: 12 [8000/28539 (28%)]\tLoss: 0.838885\n",
      "Train Epoch: 12 [9000/28539 (32%)]\tLoss: 0.651148\n",
      "Train Epoch: 12 [10000/28539 (35%)]\tLoss: 0.682810\n",
      "Train Epoch: 12 [11000/28539 (39%)]\tLoss: 0.652493\n",
      "Train Epoch: 12 [12000/28539 (42%)]\tLoss: 0.783807\n",
      "Train Epoch: 12 [13000/28539 (46%)]\tLoss: 0.722212\n",
      "Train Epoch: 12 [14000/28539 (49%)]\tLoss: 0.790509\n",
      "Train Epoch: 12 [15000/28539 (53%)]\tLoss: 0.570548\n",
      "Train Epoch: 12 [16000/28539 (56%)]\tLoss: 0.731118\n",
      "Train Epoch: 12 [17000/28539 (60%)]\tLoss: 0.661250\n",
      "Train Epoch: 12 [18000/28539 (63%)]\tLoss: 0.647049\n",
      "Train Epoch: 12 [19000/28539 (67%)]\tLoss: 0.769477\n",
      "Train Epoch: 12 [20000/28539 (70%)]\tLoss: 0.734872\n",
      "Train Epoch: 12 [21000/28539 (74%)]\tLoss: 0.688950\n",
      "Train Epoch: 12 [22000/28539 (77%)]\tLoss: 0.571936\n",
      "Train Epoch: 12 [23000/28539 (81%)]\tLoss: 0.733957\n",
      "Train Epoch: 12 [24000/28539 (84%)]\tLoss: 0.666414\n",
      "Train Epoch: 12 [25000/28539 (88%)]\tLoss: 0.682458\n",
      "Train Epoch: 12 [26000/28539 (91%)]\tLoss: 0.622176\n",
      "Train Epoch: 12 [27000/28539 (95%)]\tLoss: 0.671337\n",
      "Train Epoch: 12 [28000/28539 (98%)]\tLoss: 0.692112\n",
      "Elapsed time 11.51 minutes\n",
      "Train Epoch: 13 lr = 0.00028570262914205625\n",
      "Train Epoch: 13 [0000/28539 (0%)]\tLoss: 0.693485\n",
      "Train Epoch: 13 [1000/28539 (4%)]\tLoss: 0.842825\n",
      "Train Epoch: 13 [2000/28539 (7%)]\tLoss: 0.731462\n",
      "Train Epoch: 13 [3000/28539 (11%)]\tLoss: 0.595731\n",
      "Train Epoch: 13 [4000/28539 (14%)]\tLoss: 0.660824\n",
      "Train Epoch: 13 [5000/28539 (18%)]\tLoss: 0.649237\n",
      "Train Epoch: 13 [6000/28539 (21%)]\tLoss: 0.551861\n",
      "Train Epoch: 13 [7000/28539 (25%)]\tLoss: 0.566329\n",
      "Train Epoch: 13 [8000/28539 (28%)]\tLoss: 0.567395\n",
      "Train Epoch: 13 [9000/28539 (32%)]\tLoss: 0.548224\n",
      "Train Epoch: 13 [10000/28539 (35%)]\tLoss: 0.572745\n",
      "Train Epoch: 13 [11000/28539 (39%)]\tLoss: 0.582624\n",
      "Train Epoch: 13 [12000/28539 (42%)]\tLoss: 0.664386\n",
      "Train Epoch: 13 [13000/28539 (46%)]\tLoss: 0.596324\n",
      "Train Epoch: 13 [14000/28539 (49%)]\tLoss: 0.540570\n",
      "Train Epoch: 13 [15000/28539 (53%)]\tLoss: 0.632512\n",
      "Train Epoch: 13 [16000/28539 (56%)]\tLoss: 0.582418\n",
      "Train Epoch: 13 [17000/28539 (60%)]\tLoss: 0.792286\n",
      "Train Epoch: 13 [18000/28539 (63%)]\tLoss: 0.649248\n",
      "Train Epoch: 13 [19000/28539 (67%)]\tLoss: 0.593098\n",
      "Train Epoch: 13 [20000/28539 (70%)]\tLoss: 0.620405\n",
      "Train Epoch: 13 [21000/28539 (74%)]\tLoss: 0.476866\n",
      "Train Epoch: 13 [22000/28539 (77%)]\tLoss: 0.658523\n",
      "Train Epoch: 13 [23000/28539 (81%)]\tLoss: 0.493724\n",
      "Train Epoch: 13 [24000/28539 (84%)]\tLoss: 0.735647\n",
      "Train Epoch: 13 [25000/28539 (88%)]\tLoss: 0.912450\n",
      "Train Epoch: 13 [26000/28539 (91%)]\tLoss: 0.410920\n",
      "Train Epoch: 13 [27000/28539 (95%)]\tLoss: 0.587872\n",
      "Train Epoch: 13 [28000/28539 (98%)]\tLoss: 0.661894\n",
      "Elapsed time 11.52 minutes\n",
      "Train Epoch: 14 lr = 0.0002499884862849134\n",
      "Train Epoch: 14 [0000/28539 (0%)]\tLoss: 0.552012\n",
      "Train Epoch: 14 [1000/28539 (4%)]\tLoss: 0.561013\n",
      "Train Epoch: 14 [2000/28539 (7%)]\tLoss: 0.606195\n",
      "Train Epoch: 14 [3000/28539 (11%)]\tLoss: 0.701322\n",
      "Train Epoch: 14 [4000/28539 (14%)]\tLoss: 0.579066\n",
      "Train Epoch: 14 [5000/28539 (18%)]\tLoss: 0.558256\n",
      "Train Epoch: 14 [6000/28539 (21%)]\tLoss: 0.622863\n",
      "Train Epoch: 14 [7000/28539 (25%)]\tLoss: 0.574685\n",
      "Train Epoch: 14 [8000/28539 (28%)]\tLoss: 0.568252\n",
      "Train Epoch: 14 [9000/28539 (32%)]\tLoss: 0.531067\n",
      "Train Epoch: 14 [10000/28539 (35%)]\tLoss: 0.566408\n",
      "Train Epoch: 14 [11000/28539 (39%)]\tLoss: 0.622994\n",
      "Train Epoch: 14 [12000/28539 (42%)]\tLoss: 0.548333\n",
      "Train Epoch: 14 [13000/28539 (46%)]\tLoss: 0.597173\n",
      "Train Epoch: 14 [14000/28539 (49%)]\tLoss: 0.767784\n",
      "Train Epoch: 14 [15000/28539 (53%)]\tLoss: 0.525068\n",
      "Train Epoch: 14 [16000/28539 (56%)]\tLoss: 0.595866\n",
      "Train Epoch: 14 [17000/28539 (60%)]\tLoss: 0.678959\n",
      "Train Epoch: 14 [18000/28539 (63%)]\tLoss: 0.629256\n",
      "Train Epoch: 14 [19000/28539 (67%)]\tLoss: 0.449462\n",
      "Train Epoch: 14 [20000/28539 (70%)]\tLoss: 0.598501\n",
      "Train Epoch: 14 [21000/28539 (74%)]\tLoss: 0.558161\n",
      "Train Epoch: 14 [22000/28539 (77%)]\tLoss: 0.736741\n",
      "Train Epoch: 14 [23000/28539 (81%)]\tLoss: 0.708918\n",
      "Train Epoch: 14 [24000/28539 (84%)]\tLoss: 0.525925\n",
      "Train Epoch: 14 [25000/28539 (88%)]\tLoss: 0.611755\n",
      "Train Epoch: 14 [26000/28539 (91%)]\tLoss: 0.578370\n",
      "Train Epoch: 14 [27000/28539 (95%)]\tLoss: 0.601165\n",
      "Train Epoch: 14 [28000/28539 (98%)]\tLoss: 0.589090\n",
      "Elapsed time 11.52 minutes\n",
      "Train Epoch: 15 lr = 0.00021427434342777057\n",
      "Train Epoch: 15 [0000/28539 (0%)]\tLoss: 0.575443\n",
      "Train Epoch: 15 [1000/28539 (4%)]\tLoss: 0.692997\n",
      "Train Epoch: 15 [2000/28539 (7%)]\tLoss: 0.606317\n",
      "Train Epoch: 15 [3000/28539 (11%)]\tLoss: 0.511246\n",
      "Train Epoch: 15 [4000/28539 (14%)]\tLoss: 0.489313\n",
      "Train Epoch: 15 [5000/28539 (18%)]\tLoss: 0.599472\n",
      "Train Epoch: 15 [6000/28539 (21%)]\tLoss: 0.616312\n",
      "Train Epoch: 15 [7000/28539 (25%)]\tLoss: 0.454035\n",
      "Train Epoch: 15 [8000/28539 (28%)]\tLoss: 0.570240\n",
      "Train Epoch: 15 [9000/28539 (32%)]\tLoss: 0.518361\n",
      "Train Epoch: 15 [10000/28539 (35%)]\tLoss: 0.479180\n",
      "Train Epoch: 15 [11000/28539 (39%)]\tLoss: 0.562243\n",
      "Train Epoch: 15 [12000/28539 (42%)]\tLoss: 0.474422\n",
      "Train Epoch: 15 [13000/28539 (46%)]\tLoss: 0.452054\n",
      "Train Epoch: 15 [14000/28539 (49%)]\tLoss: 0.477826\n",
      "Train Epoch: 15 [15000/28539 (53%)]\tLoss: 0.628452\n",
      "Train Epoch: 15 [16000/28539 (56%)]\tLoss: 0.550332\n",
      "Train Epoch: 15 [17000/28539 (60%)]\tLoss: 0.453896\n",
      "Train Epoch: 15 [18000/28539 (63%)]\tLoss: 0.646162\n",
      "Train Epoch: 15 [19000/28539 (67%)]\tLoss: 0.481728\n",
      "Train Epoch: 15 [20000/28539 (70%)]\tLoss: 0.649727\n",
      "Train Epoch: 15 [21000/28539 (74%)]\tLoss: 0.674952\n",
      "Train Epoch: 15 [22000/28539 (77%)]\tLoss: 0.642595\n",
      "Train Epoch: 15 [23000/28539 (81%)]\tLoss: 0.707235\n",
      "Train Epoch: 15 [24000/28539 (84%)]\tLoss: 0.577219\n",
      "Train Epoch: 15 [25000/28539 (88%)]\tLoss: 0.520161\n",
      "Train Epoch: 15 [26000/28539 (91%)]\tLoss: 0.449911\n",
      "Train Epoch: 15 [27000/28539 (95%)]\tLoss: 0.621342\n",
      "Train Epoch: 15 [28000/28539 (98%)]\tLoss: 0.572563\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Test set: Average loss: 0.4863, Average CER: 0.143498 Average WER: 0.4382\n",
      "\n",
      "\n",
      "EXAMPLE\n",
      "GT:\n",
      "i love thee with a love i seemed to lose with my lost saints i love thee with the breath smiles tears of all my life and if god choose i shall but love thee better after death\n",
      "\n",
      "Network output:\n",
      "i love the with a lae i seemed to loe with my lost sans i love te with the breath smile t hyers of all mi life and if god chos i shalw but love the better after death\n",
      "Elapsed time 17.99 minutes\n",
      "Train Epoch: 16 lr = 0.00017856020057062773\n",
      "Train Epoch: 16 [0000/28539 (0%)]\tLoss: 0.554223\n",
      "Train Epoch: 16 [1000/28539 (4%)]\tLoss: 0.581584\n",
      "Train Epoch: 16 [2000/28539 (7%)]\tLoss: 0.526384\n",
      "Train Epoch: 16 [3000/28539 (11%)]\tLoss: 0.441205\n",
      "Train Epoch: 16 [4000/28539 (14%)]\tLoss: 0.503539\n",
      "Train Epoch: 16 [5000/28539 (18%)]\tLoss: 0.630283\n",
      "Train Epoch: 16 [6000/28539 (21%)]\tLoss: 0.550811\n",
      "Train Epoch: 16 [7000/28539 (25%)]\tLoss: 0.547448\n",
      "Train Epoch: 16 [8000/28539 (28%)]\tLoss: 0.455131\n",
      "Train Epoch: 16 [9000/28539 (32%)]\tLoss: 0.630445\n",
      "Train Epoch: 16 [10000/28539 (35%)]\tLoss: 0.536621\n",
      "Train Epoch: 16 [11000/28539 (39%)]\tLoss: 0.558437\n",
      "Train Epoch: 16 [12000/28539 (42%)]\tLoss: 0.533057\n",
      "Train Epoch: 16 [13000/28539 (46%)]\tLoss: 0.571897\n",
      "Train Epoch: 16 [14000/28539 (49%)]\tLoss: 0.525183\n",
      "Train Epoch: 16 [15000/28539 (53%)]\tLoss: 0.670204\n",
      "Train Epoch: 16 [16000/28539 (56%)]\tLoss: 0.507912\n",
      "Train Epoch: 16 [17000/28539 (60%)]\tLoss: 0.483980\n",
      "Train Epoch: 16 [18000/28539 (63%)]\tLoss: 0.628834\n",
      "Train Epoch: 16 [19000/28539 (67%)]\tLoss: 0.519416\n",
      "Train Epoch: 16 [20000/28539 (70%)]\tLoss: 0.661339\n",
      "Train Epoch: 16 [21000/28539 (74%)]\tLoss: 0.629421\n",
      "Train Epoch: 16 [22000/28539 (77%)]\tLoss: 0.603009\n",
      "Train Epoch: 16 [23000/28539 (81%)]\tLoss: 0.555478\n",
      "Train Epoch: 16 [24000/28539 (84%)]\tLoss: 0.599859\n",
      "Train Epoch: 16 [25000/28539 (88%)]\tLoss: 0.610331\n",
      "Train Epoch: 16 [26000/28539 (91%)]\tLoss: 0.547268\n",
      "Train Epoch: 16 [27000/28539 (95%)]\tLoss: 0.557181\n",
      "Train Epoch: 16 [28000/28539 (98%)]\tLoss: 0.464187\n",
      "Elapsed time 11.51 minutes\n",
      "Train Epoch: 17 lr = 0.00014284605771348484\n",
      "Train Epoch: 17 [0000/28539 (0%)]\tLoss: 0.497627\n",
      "Train Epoch: 17 [1000/28539 (4%)]\tLoss: 0.527399\n",
      "Train Epoch: 17 [2000/28539 (7%)]\tLoss: 0.488118\n",
      "Train Epoch: 17 [3000/28539 (11%)]\tLoss: 0.725425\n",
      "Train Epoch: 17 [4000/28539 (14%)]\tLoss: 0.569228\n",
      "Train Epoch: 17 [5000/28539 (18%)]\tLoss: 0.556740\n",
      "Train Epoch: 17 [6000/28539 (21%)]\tLoss: 0.620620\n",
      "Train Epoch: 17 [7000/28539 (25%)]\tLoss: 0.633949\n",
      "Train Epoch: 17 [8000/28539 (28%)]\tLoss: 0.481183\n",
      "Train Epoch: 17 [9000/28539 (32%)]\tLoss: 0.426643\n",
      "Train Epoch: 17 [10000/28539 (35%)]\tLoss: 0.528497\n",
      "Train Epoch: 17 [11000/28539 (39%)]\tLoss: 0.497744\n",
      "Train Epoch: 17 [12000/28539 (42%)]\tLoss: 0.633371\n",
      "Train Epoch: 17 [13000/28539 (46%)]\tLoss: 0.718681\n",
      "Train Epoch: 17 [14000/28539 (49%)]\tLoss: 0.480323\n",
      "Train Epoch: 17 [15000/28539 (53%)]\tLoss: 0.588620\n",
      "Train Epoch: 17 [16000/28539 (56%)]\tLoss: 0.371012\n",
      "Train Epoch: 17 [17000/28539 (60%)]\tLoss: 0.567272\n",
      "Train Epoch: 17 [18000/28539 (63%)]\tLoss: 0.490117\n",
      "Train Epoch: 17 [19000/28539 (67%)]\tLoss: 0.463796\n",
      "Train Epoch: 17 [20000/28539 (70%)]\tLoss: 0.559302\n",
      "Train Epoch: 17 [21000/28539 (74%)]\tLoss: 0.568431\n",
      "Train Epoch: 17 [22000/28539 (77%)]\tLoss: 0.494466\n",
      "Train Epoch: 17 [23000/28539 (81%)]\tLoss: 0.532279\n",
      "Train Epoch: 17 [24000/28539 (84%)]\tLoss: 0.595818\n",
      "Train Epoch: 17 [25000/28539 (88%)]\tLoss: 0.540874\n",
      "Train Epoch: 17 [26000/28539 (91%)]\tLoss: 0.575495\n",
      "Train Epoch: 17 [27000/28539 (95%)]\tLoss: 0.642520\n",
      "Train Epoch: 17 [28000/28539 (98%)]\tLoss: 0.465015\n",
      "Elapsed time 11.51 minutes\n",
      "Train Epoch: 18 lr = 0.000107131914856342\n",
      "Train Epoch: 18 [0000/28539 (0%)]\tLoss: 0.593240\n",
      "Train Epoch: 18 [1000/28539 (4%)]\tLoss: 0.443324\n",
      "Train Epoch: 18 [2000/28539 (7%)]\tLoss: 0.433888\n",
      "Train Epoch: 18 [3000/28539 (11%)]\tLoss: 0.486012\n",
      "Train Epoch: 18 [4000/28539 (14%)]\tLoss: 0.476585\n",
      "Train Epoch: 18 [5000/28539 (18%)]\tLoss: 0.594567\n",
      "Train Epoch: 18 [6000/28539 (21%)]\tLoss: 0.450270\n",
      "Train Epoch: 18 [7000/28539 (25%)]\tLoss: 0.521343\n",
      "Train Epoch: 18 [8000/28539 (28%)]\tLoss: 0.408470\n",
      "Train Epoch: 18 [9000/28539 (32%)]\tLoss: 0.560970\n",
      "Train Epoch: 18 [10000/28539 (35%)]\tLoss: 0.473573\n",
      "Train Epoch: 18 [11000/28539 (39%)]\tLoss: 0.471442\n",
      "Train Epoch: 18 [12000/28539 (42%)]\tLoss: 0.461031\n",
      "Train Epoch: 18 [13000/28539 (46%)]\tLoss: 0.479284\n",
      "Train Epoch: 18 [14000/28539 (49%)]\tLoss: 0.501817\n",
      "Train Epoch: 18 [15000/28539 (53%)]\tLoss: 0.479364\n",
      "Train Epoch: 18 [16000/28539 (56%)]\tLoss: 0.427988\n",
      "Train Epoch: 18 [17000/28539 (60%)]\tLoss: 0.478300\n",
      "Train Epoch: 18 [18000/28539 (63%)]\tLoss: 0.533403\n",
      "Train Epoch: 18 [19000/28539 (67%)]\tLoss: 0.487191\n",
      "Train Epoch: 18 [20000/28539 (70%)]\tLoss: 0.474080\n",
      "Train Epoch: 18 [21000/28539 (74%)]\tLoss: 0.592967\n",
      "Train Epoch: 18 [22000/28539 (77%)]\tLoss: 0.412926\n",
      "Train Epoch: 18 [23000/28539 (81%)]\tLoss: 0.487225\n",
      "Train Epoch: 18 [24000/28539 (84%)]\tLoss: 0.567852\n",
      "Train Epoch: 18 [25000/28539 (88%)]\tLoss: 0.512849\n",
      "Train Epoch: 18 [26000/28539 (91%)]\tLoss: 0.441442\n",
      "Train Epoch: 18 [27000/28539 (95%)]\tLoss: 0.606499\n",
      "Train Epoch: 18 [28000/28539 (98%)]\tLoss: 0.520397\n",
      "Elapsed time 11.51 minutes\n",
      "Train Epoch: 19 lr = 7.141777199919916e-05\n",
      "Train Epoch: 19 [0000/28539 (0%)]\tLoss: 0.407831\n",
      "Train Epoch: 19 [1000/28539 (4%)]\tLoss: 0.469443\n",
      "Train Epoch: 19 [2000/28539 (7%)]\tLoss: 0.519701\n",
      "Train Epoch: 19 [3000/28539 (11%)]\tLoss: 0.390055\n",
      "Train Epoch: 19 [4000/28539 (14%)]\tLoss: 0.470062\n",
      "Train Epoch: 19 [5000/28539 (18%)]\tLoss: 0.398841\n",
      "Train Epoch: 19 [6000/28539 (21%)]\tLoss: 0.580176\n",
      "Train Epoch: 19 [7000/28539 (25%)]\tLoss: 0.384344\n",
      "Train Epoch: 19 [8000/28539 (28%)]\tLoss: 0.367976\n",
      "Train Epoch: 19 [9000/28539 (32%)]\tLoss: 0.470799\n",
      "Train Epoch: 19 [10000/28539 (35%)]\tLoss: 0.492520\n",
      "Train Epoch: 19 [11000/28539 (39%)]\tLoss: 0.577011\n",
      "Train Epoch: 19 [12000/28539 (42%)]\tLoss: 0.515154\n",
      "Train Epoch: 19 [13000/28539 (46%)]\tLoss: 0.565553\n",
      "Train Epoch: 19 [14000/28539 (49%)]\tLoss: 0.365260\n",
      "Train Epoch: 19 [15000/28539 (53%)]\tLoss: 0.553710\n",
      "Train Epoch: 19 [16000/28539 (56%)]\tLoss: 0.571674\n",
      "Train Epoch: 19 [17000/28539 (60%)]\tLoss: 0.388221\n",
      "Train Epoch: 19 [18000/28539 (63%)]\tLoss: 0.462990\n",
      "Train Epoch: 19 [19000/28539 (67%)]\tLoss: 0.598676\n",
      "Train Epoch: 19 [20000/28539 (70%)]\tLoss: 0.460096\n",
      "Train Epoch: 19 [21000/28539 (74%)]\tLoss: 0.479026\n",
      "Train Epoch: 19 [22000/28539 (77%)]\tLoss: 0.468830\n",
      "Train Epoch: 19 [23000/28539 (81%)]\tLoss: 0.490599\n",
      "Train Epoch: 19 [24000/28539 (84%)]\tLoss: 0.572055\n",
      "Train Epoch: 19 [25000/28539 (88%)]\tLoss: 0.484011\n",
      "Train Epoch: 19 [26000/28539 (91%)]\tLoss: 0.473671\n",
      "Train Epoch: 19 [27000/28539 (95%)]\tLoss: 0.555616\n",
      "Train Epoch: 19 [28000/28539 (98%)]\tLoss: 0.532933\n",
      "Elapsed time 11.53 minutes\n",
      "Train Epoch: 20 lr = 3.570362914205626e-05\n",
      "Train Epoch: 20 [0000/28539 (0%)]\tLoss: 0.568334\n",
      "Train Epoch: 20 [1000/28539 (4%)]\tLoss: 0.501324\n",
      "Train Epoch: 20 [2000/28539 (7%)]\tLoss: 0.455947\n",
      "Train Epoch: 20 [3000/28539 (11%)]\tLoss: 0.505088\n",
      "Train Epoch: 20 [4000/28539 (14%)]\tLoss: 0.542068\n",
      "Train Epoch: 20 [5000/28539 (18%)]\tLoss: 0.483363\n",
      "Train Epoch: 20 [6000/28539 (21%)]\tLoss: 0.578915\n",
      "Train Epoch: 20 [7000/28539 (25%)]\tLoss: 0.419380\n",
      "Train Epoch: 20 [8000/28539 (28%)]\tLoss: 0.446196\n",
      "Train Epoch: 20 [9000/28539 (32%)]\tLoss: 0.508247\n",
      "Train Epoch: 20 [10000/28539 (35%)]\tLoss: 0.574040\n",
      "Train Epoch: 20 [11000/28539 (39%)]\tLoss: 0.461061\n",
      "Train Epoch: 20 [12000/28539 (42%)]\tLoss: 0.520780\n",
      "Train Epoch: 20 [13000/28539 (46%)]\tLoss: 0.405697\n",
      "Train Epoch: 20 [14000/28539 (49%)]\tLoss: 0.528955\n",
      "Train Epoch: 20 [15000/28539 (53%)]\tLoss: 0.621207\n",
      "Train Epoch: 20 [16000/28539 (56%)]\tLoss: 0.410996\n",
      "Train Epoch: 20 [17000/28539 (60%)]\tLoss: 0.528922\n",
      "Train Epoch: 20 [18000/28539 (63%)]\tLoss: 0.703022\n",
      "Train Epoch: 20 [19000/28539 (67%)]\tLoss: 0.523189\n",
      "Train Epoch: 20 [20000/28539 (70%)]\tLoss: 0.340997\n",
      "Train Epoch: 20 [21000/28539 (74%)]\tLoss: 0.523781\n",
      "Train Epoch: 20 [22000/28539 (77%)]\tLoss: 0.532698\n",
      "Train Epoch: 20 [23000/28539 (81%)]\tLoss: 0.536811\n",
      "Train Epoch: 20 [24000/28539 (84%)]\tLoss: 0.574051\n",
      "Train Epoch: 20 [25000/28539 (88%)]\tLoss: 0.422668\n",
      "Train Epoch: 20 [26000/28539 (91%)]\tLoss: 0.378023\n",
      "Train Epoch: 20 [27000/28539 (95%)]\tLoss: 0.487338\n",
      "Train Epoch: 20 [28000/28539 (98%)]\tLoss: 0.429663\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Test set: Average loss: 0.4560, Average CER: 0.132092 Average WER: 0.4056\n",
      "\n",
      "\n",
      "EXAMPLE\n",
      "GT:\n",
      "i love thee with a love i seemed to lose with my lost saints i love thee with the breath smiles tears of all my life and if god choose i shall but love thee better after death\n",
      "\n",
      "Network output:\n",
      "i love the with a love i seemed to loe with my lost sans i love te with the breath smiles t heres of all my life and if god chos i shal but love the better after death\n",
      "Elapsed time 18.04 minutes\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a63X0U3Xw7uf"
   },
   "source": [
    "### [EXERCISE 4]:\n",
    "\n",
    "Describe why the input parameter (blank=28) means when initializating the CTC Loss. Explain the utility of this element and why the value is 28."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kyz6rHHbw7ug"
   },
   "source": [
    "### EX 4 - QUESTION 1\n",
    "\n",
    "> Classical speech recognition algorithms would need the transcript text to be aligned with the audio before training, and the model would be taught to predict specific labels at specific intervals. Forcing every input step to correspond to some output rarely makes sense. The input may contain periods of silence with no matching output, or we sometimes have no way to produce outputs with multiple characters in a row. \n",
    "\n",
    "> The CTC loss function is unique in that it makes it possible to avoid this process. During training, our model will learn to align the transcript by itself. The \"**blank**\" label added by CTC, also known as epsilon, allows the model to identify that a particular audio frame did not produce a character. Or when dealing with repeated characters, if a word has two of the same character in a row, then a valid alignment must have a blank (or epsilon) between them. With this rule in place, we can differentiate between alignments which collapse correctly and incorrectly when merging.\n",
    "\n",
    "> As our model predicts 28 classes, the blank is set to 28, which means that the blank label is the class with index 28."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HROoXGjsVdfM"
   },
   "source": [
    "### Testing Models\n",
    "\n",
    "The training process to learn the optimal parameters of an ASR model is slow and may take several hours. Hence, we are providing you with 3 models that can be directly tested as long as the previous required code is correct. If you do not have time to train your own models, you can ommit the previous cell and directly jump the next one. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VIjowL6XVdfN"
   },
   "outputs": [],
   "source": [
    "def get_model_path(spath, params):\n",
    "    \n",
    "    if params.get('use_gru'):\n",
    "        if params.get('bidirectional'):\n",
    "            model_name = '/model_bigru.tar'\n",
    "        else:\n",
    "            model_name = '/model_gru.tar'\n",
    "    else:\n",
    "        model_name = '/model_rnn.tar'\n",
    "    \n",
    "    return spath + model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cH4fxPR6VdfN"
   },
   "outputs": [],
   "source": [
    "#This cell is to load and evaluate a model that has been previously trained and saved to disk\n",
    "\n",
    "def testloop(model_path, model_params, test_params, device, use_cuda, num_workers=2):\n",
    "    torch.manual_seed(7)\n",
    "\n",
    "    test_dataset =  LibriSpeech(test_params['db_path'], \"test\", model_params['n_feats'])\n",
    "    test_loader = get_dataloader(\n",
    "        test_dataset,\n",
    "        batch_size=test_params['batch_size'],\n",
    "        shuffle=False, use_cuda=use_cuda,\n",
    "        num_workers=num_workers\n",
    "    )\n",
    "\n",
    "    model = get_sr_model(SpeechRecognitionModel, model_params, device)\n",
    "\n",
    "    print(100 * '-', f'\\nModel: {model_params[\"name\"]}')\n",
    "    print('Num Model Parameters:', sum([param.nelement() for param in model.parameters()]))\n",
    "\n",
    "    if os.path.exists(model_path):\n",
    "        print(f'Loading pre-trained network from {model_path}')\n",
    "        model.load_state_dict(torch.load(model_path), strict=True)\n",
    "\n",
    "    return test(\n",
    "        model, device, test_loader,\n",
    "        criterion=nn.CTCLoss(blank=28).to(device)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sc-LfWeyw7ug"
   },
   "source": [
    "### [EXERCISE 5]\n",
    "\n",
    "Evaluate the ASR considering 3 options:\n",
    "- a) The original ASR model with the vainilla RNN\n",
    "- b) The ASR model, but substituting the vainilla RNN by a GRU layer\n",
    "- c) The ASR model, but substituting the vainilla RNN by a bidirectional GRU layer\n",
    "\n",
    "Compare the results in terms of Average CER, WER and Loss, and include the GT and output senteces provided by the three options. Include a discussion about the results explaining why some options are better than others."
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "test_params = {\n",
    "    \"batch_size\": 32,\n",
    "    \"db_path\": data_path,\n",
    "}\n",
    "rnn_params = {\n",
    "    'name': 'rnn',\n",
    "    \"n_cnn_layers\": 2,\n",
    "    \"n_rnn_layers\": 2,\n",
    "    \"rnn_dim\": 512,\n",
    "    \"n_class\": 29,\n",
    "    \"n_feats\": 128,\n",
    "    \"stride\": 2,\n",
    "    \"dropout\": 0.0,\n",
    "    \"use_gru\": False,\n",
    "    \"bidirectional\": False,\n",
    "}\n",
    "\n",
    "gru_params = rnn_params.copy()\n",
    "gru_params['name'] = 'gru'\n",
    "gru_params['use_gru'] = True\n",
    "\n",
    "bigru_params = gru_params.copy()\n",
    "bigru_params['name'] = 'bigru'\n",
    "bigru_params['bidirectional'] = True\n",
    "\n",
    "models_params = [rnn_params, gru_params, bigru_params]\n",
    "\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "model_results = {}\n",
    "for mparams in models_params:\n",
    "\n",
    "    st = time.time()\n",
    "\n",
    "    results, avg_metrics = testloop(\n",
    "        f'./data/weights/model_{mparams.get(\"name\")}_epoch_20.tar',\n",
    "        mparams, test_params,\n",
    "        device, use_cuda\n",
    "    )\n",
    "    print(f'\\nElapsed time for {mparams.get(\"name\").upper()} model: {(time.time() - st)//60}m {int((time.time() - st)%60)}s\\n')\n",
    "\n",
    "    model_results[mparams.get('name')] = [results, avg_metrics]\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LcFkBxAh2NrP",
    "outputId": "a108a662-3f85-4470-8a9f-91d97714488b"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "---------------------------------------------------------------------------------------------------- \n",
      "Model: rnn\n",
      "Num Model Parameters 2417117\n",
      "Loading pre-trained network from ./data/weights/model_rnn_epoch_20.tar\n",
      "\n",
      "Evaluating...\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/torchaudio/functional/functional.py:595: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (128) may be set too high. Or, the value for `n_freqs` (201) may be set too low.\n",
      "  \"At least one mel filterbank has all zero values. \"\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Test set: Average loss: 0.7824, Average CER: 0.241363 Average WER: 0.6802\n",
      "\n",
      "\n",
      "EXAMPLE\n",
      "GT:\n",
      "i love thee with a love i seemed to lose with my lost saints i love thee with the breath smiles tears of all my life and if god choose i shall but love thee better after death\n",
      "\n",
      "Network output:\n",
      "i  love the with a love i seemed to thee with my lost sans i love be with the bre smiile ye ares of al mi elife and if go ches i shawd byt loved the better after dath\n",
      "\n",
      "Elapsed time for RNN model: 6.0m 21s\n",
      "\n",
      "---------------------------------------------------------------------------------------------------- \n",
      "Model: gru\n",
      "Num Model Parameters 4518365\n",
      "Loading pre-trained network from ./data/weights/model_gru_epoch_20.tar\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Test set: Average loss: 0.6142, Average CER: 0.185658 Average WER: 0.5534\n",
      "\n",
      "\n",
      "EXAMPLE\n",
      "GT:\n",
      "i love thee with a love i seemed to lose with my lost saints i love thee with the breath smiles tears of all my life and if god choose i shall but love thee better after death\n",
      "\n",
      "Network output:\n",
      "i leve the with a love i seemed to loe with mi lost sains i love the with the breaath smalesear of al mynalife and if gad cshes i shall but love the better after daath\n",
      "\n",
      "Elapsed time for GRU model: 6.0m 28s\n",
      "\n",
      "---------------------------------------------------------------------------------------------------- \n",
      "Model: bigru\n",
      "Num Model Parameters 9506269\n",
      "Loading pre-trained network from ./data/weights/model_bigru_epoch_20.tar\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Test set: Average loss: 0.4565, Average CER: 0.132042 Average WER: 0.4054\n",
      "\n",
      "\n",
      "EXAMPLE\n",
      "GT:\n",
      "i love thee with a love i seemed to lose with my lost saints i love thee with the breath smiles tears of all my life and if god choose i shall but love thee better after death\n",
      "\n",
      "Network output:\n",
      "i love the with a love i seemed to loe with my lost sans i love te with the breath smiles t heres of all my life and if god chos i shal but love the better after death\n",
      "\n",
      "Elapsed time for BIGRU model: 6.0m 36s\n",
      "\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "def display_results(results, n_samples=5):\n",
    "\n",
    "    for model, (examples, avgs) in results.items():\n",
    "        print(100 * \"-\", f'\\n\\nMODEL: {model.upper()}')\n",
    "        [print(f'{k}: {v}') for k, v in zip(('Avg. CER', 'Avg. WER', 'Avg. Loss'), avgs)]\n",
    "\n",
    "        print(f'\\nEXAMPLES ({n_samples})')\n",
    "        for (gt, pred, cer, wer) in examples[:n_samples]:\n",
    "            print(f'Ground Truth: {gt}')\n",
    "            print(f'Prediction: {pred}')\n",
    "            print(f'CER: {cer}')\n",
    "            print(f'WER: {wer}', end='\\n\\n')\n",
    "\n",
    "    print(100 * '-')"
   ],
   "metadata": {
    "id": "JYdqwaxr2SJB"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "display_results(model_results, n_samples=5)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cQbsaQRGFuea",
    "outputId": "595577df-29ec-48a8-dc32-dbba6d543004"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "---------------------------------------------------------------------------------------------------- \n",
      "\n",
      "MODEL: RNN\n",
      "Avg. CER: 0.24136258807830188\n",
      "Avg. WER: 0.6801813814750154\n",
      "Avg. Loss: 0.7824004670468775\n",
      "\n",
      "EXAMPLES (5)\n",
      "Ground Truth: why a tongue impress'd with honey from every wind\n",
      "Prediction: wy at tong inmpressd with huny from every wind \n",
      "CER: 0.27848101265822783\n",
      "WER: 0.7142857142857143\n",
      "\n",
      "Ground Truth: why an ear a whirlpool fierce to draw creations in\n",
      "Prediction: wi an ear a worl pop fercse to drok reeations bem \n",
      "CER: 0.14285714285714285\n",
      "WER: 0.5\n",
      "\n",
      "Ground Truth: all is said without a word\n",
      "Prediction: all was seid without a worrd \n",
      "CER: 0.19230769230769232\n",
      "WER: 0.7222222222222222\n",
      "\n",
      "Ground Truth: i sit beneath thy looks as children do in the noon sun with souls that tremble through their happy eyelids from an unaverred yet prodigal inward joy\n",
      "Prediction: i set bene thi looks as choltren do in the newn son with sols that chremble thrugh their happy i amlys from an un ofverd yet pronicle inword joy\n",
      "CER: 0.47058823529411764\n",
      "WER: 1.1428571428571428\n",
      "\n",
      "Ground Truth: i did not wrong myself so but i placed a wrong on thee\n",
      "Prediction: i did not rong my selvf so but i placsed aron on vhe \n",
      "CER: 0.3728813559322034\n",
      "WER: 1.1818181818181819\n",
      "\n",
      "---------------------------------------------------------------------------------------------------- \n",
      "\n",
      "MODEL: GRU\n",
      "Avg. CER: 0.18565782548377424\n",
      "Avg. WER: 0.5534308275578461\n",
      "Avg. Loss: 0.6142186773259465\n",
      "\n",
      "EXAMPLES (5)\n",
      "Ground Truth: why a tongue impress'd with honey from every wind\n",
      "Prediction: why at tone impressed with huney from every wind\n",
      "CER: 0.18354430379746836\n",
      "WER: 0.5714285714285714\n",
      "\n",
      "Ground Truth: why an ear a whirlpool fierce to draw creations in\n",
      "Prediction: why in ear a worl pood ferce to droc creations in\n",
      "CER: 0.14285714285714285\n",
      "WER: 0.375\n",
      "\n",
      "Ground Truth: all is said without a word\n",
      "Prediction: always sed wenthout a word \n",
      "CER: 0.1346153846153846\n",
      "WER: 0.5555555555555556\n",
      "\n",
      "Ground Truth: i sit beneath thy looks as children do in the noon sun with souls that tremble through their happy eyelids from an unaverred yet prodigal inward joy\n",
      "Prediction: i siok the ne thi looks as childerin do win the newon son with souls that tremble through their happy ilads from in unofverd yet promical inward joy\n",
      "CER: 0.29411764705882354\n",
      "WER: 0.8571428571428571\n",
      "\n",
      "Ground Truth: i did not wrong myself so but i placed a wrong on thee\n",
      "Prediction: i did not rong myself so by placed aron on the\n",
      "CER: 0.3050847457627119\n",
      "WER: 0.9090909090909091\n",
      "\n",
      "---------------------------------------------------------------------------------------------------- \n",
      "\n",
      "MODEL: BIGRU\n",
      "Avg. CER: 0.13204238996881698\n",
      "Avg. WER: 0.40535667868742464\n",
      "Avg. Loss: 0.4565326240731448\n",
      "\n",
      "EXAMPLES (5)\n",
      "Ground Truth: why a tongue impress'd with honey from every wind\n",
      "Prediction: why at tong impressed with huny from every wind\n",
      "CER: 0.189873417721519\n",
      "WER: 0.5\n",
      "\n",
      "Ground Truth: why an ear a whirlpool fierce to draw creations in\n",
      "Prediction: wyan ear a worl po fierce to dracreations in\n",
      "CER: 0.09523809523809523\n",
      "WER: 0.375\n",
      "\n",
      "Ground Truth: all is said without a word\n",
      "Prediction: always said without a word\n",
      "CER: 0.057692307692307696\n",
      "WER: 0.2777777777777778\n",
      "\n",
      "Ground Truth: i sit beneath thy looks as children do in the noon sun with souls that tremble through their happy eyelids from an unaverred yet prodigal inward joy\n",
      "Prediction: i sat beneath thy looks as children do in the noon son with souls that tremble through their happy ietlads from an unoverd yet promicle inwar joy\n",
      "CER: 0.38235294117647056\n",
      "WER: 0.5714285714285714\n",
      "\n",
      "Ground Truth: i did not wrong myself so but i placed a wrong on thee\n",
      "Prediction: i did not wrong myself so byt i placed arong on vhe\n",
      "CER: 0.2711864406779661\n",
      "WER: 0.6363636363636364\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z8imPN_vw7uh"
   },
   "source": [
    "### EX 5 - QUESTION 1\n",
    "\n",
    "> As seen in the **results printed just above**, there is a clear difference in accuracy between the three models. **The most accurate is the Bidirectional GRU**, followed by the GRU and finally the vanilla RNN. This makes sense, since the GRU is a variation of the conventional RNN specifically conceived to solve the Vanishing-Exploding gradients problem, and, within it, the bidirectional is an even more advanced concept. It is therefore logical that the more specifically the architecture is designed, the better it will be at solving the problem, and so it is.\n",
    "\n",
    "> On the other hand, we have found that in terms of time consumption, the 3 are really similar in the test stage, so that once trained, it makes sense to use the Bidirectional GRU. However, we have noticed that **during the training phase the computational cost is directly proportional to the quality of the posterior predicted results**, which also makes sense within the explanatory context of the previous paragraph. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tatUS1dWw7uh"
   },
   "source": [
    "### [EVALUATION]\n",
    "\n",
    "Submit this notebook (executed) with your results to the questions by December 26th."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "QFHaKO4l1Q3G",
    "s4x0XsvUPkH_",
    "a63X0U3Xw7uf",
    "kyz6rHHbw7ug",
    "Z8imPN_vw7uh",
    "tatUS1dWw7uh"
   ],
   "name": "LS7_Speech_Recognition_CNN-RNN_100406602_100406634.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "d37d7201fc334f7ba2676f1f59dd4ad8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_view_name": "HBoxView",
      "_dom_classes": [],
      "_model_name": "HBoxModel",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "box_style": "",
      "layout": "IPY_MODEL_315ce3326a34491ba50591a79a0a10ff",
      "_model_module": "@jupyter-widgets/controls",
      "children": [
       "IPY_MODEL_412dbe9081924145ba9950f07e4e7dea",
       "IPY_MODEL_dfa664d9b2c740cf838c422d569a44c3",
       "IPY_MODEL_70fca4038c1b4f9a9d572f6626a6d30a"
      ]
     }
    },
    "315ce3326a34491ba50591a79a0a10ff": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "412dbe9081924145ba9950f07e4e7dea": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_view_name": "HTMLView",
      "style": "IPY_MODEL_8f686644fae946888b53f4a8d03edde1",
      "_dom_classes": [],
      "description": "",
      "_model_name": "HTMLModel",
      "placeholder": "​",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": "100%",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_afc4af15e9f24f0085ee5ebc40bd63ae"
     }
    },
    "dfa664d9b2c740cf838c422d569a44c3": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_view_name": "ProgressView",
      "style": "IPY_MODEL_2137b72ece444e8ea5a975aa4c2a3db4",
      "_dom_classes": [],
      "description": "",
      "_model_name": "FloatProgressModel",
      "bar_style": "success",
      "max": 6387309499,
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": 6387309499,
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "orientation": "horizontal",
      "min": 0,
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_9e323d0d45a346148a71f2e597a7437e"
     }
    },
    "70fca4038c1b4f9a9d572f6626a6d30a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_view_name": "HTMLView",
      "style": "IPY_MODEL_43046efc6c8f4f9fafe06f337bb36640",
      "_dom_classes": [],
      "description": "",
      "_model_name": "HTMLModel",
      "placeholder": "​",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": " 5.95G/5.95G [04:56&lt;00:00, 22.4MB/s]",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_34c9920073ee40eb9acd456662b306f4"
     }
    },
    "8f686644fae946888b53f4a8d03edde1": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "DescriptionStyleModel",
      "description_width": "",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "afc4af15e9f24f0085ee5ebc40bd63ae": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "2137b72ece444e8ea5a975aa4c2a3db4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "ProgressStyleModel",
      "description_width": "",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "bar_color": null,
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "9e323d0d45a346148a71f2e597a7437e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "43046efc6c8f4f9fafe06f337bb36640": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "DescriptionStyleModel",
      "description_width": "",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "34c9920073ee40eb9acd456662b306f4": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "306d8a765ebb43e7b6784db82ee96883": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_view_name": "HBoxView",
      "_dom_classes": [],
      "_model_name": "HBoxModel",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "box_style": "",
      "layout": "IPY_MODEL_2d7086f1c100435a8385ac45678cc951",
      "_model_module": "@jupyter-widgets/controls",
      "children": [
       "IPY_MODEL_94a0fe0fb79843f098157788a0f9ccfb",
       "IPY_MODEL_01c9791876b64339a3b056e602f8e1e7",
       "IPY_MODEL_0ac6fac5bbc5484c9cb4ac7b007f1c32"
      ]
     }
    },
    "2d7086f1c100435a8385ac45678cc951": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "94a0fe0fb79843f098157788a0f9ccfb": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_view_name": "HTMLView",
      "style": "IPY_MODEL_0dd304893e7b407eac35b48f5dc24836",
      "_dom_classes": [],
      "description": "",
      "_model_name": "HTMLModel",
      "placeholder": "​",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": "100%",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_eb8dfaef30e64146a869fb5f5aa889dd"
     }
    },
    "01c9791876b64339a3b056e602f8e1e7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_view_name": "ProgressView",
      "style": "IPY_MODEL_37c013f5f27344d8ad740b672db2211f",
      "_dom_classes": [],
      "description": "",
      "_model_name": "FloatProgressModel",
      "bar_style": "success",
      "max": 346663984,
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": 346663984,
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "orientation": "horizontal",
      "min": 0,
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_cbf1d9917e8642eea2a5a9280e6889f8"
     }
    },
    "0ac6fac5bbc5484c9cb4ac7b007f1c32": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_view_name": "HTMLView",
      "style": "IPY_MODEL_f998046e990941e492cfa7e2029a2a9f",
      "_dom_classes": [],
      "description": "",
      "_model_name": "HTMLModel",
      "placeholder": "​",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": " 331M/331M [00:18&lt;00:00, 19.7MB/s]",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_69f0382e202b43d682193d06842677e6"
     }
    },
    "0dd304893e7b407eac35b48f5dc24836": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "DescriptionStyleModel",
      "description_width": "",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "eb8dfaef30e64146a869fb5f5aa889dd": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "37c013f5f27344d8ad740b672db2211f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "ProgressStyleModel",
      "description_width": "",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "bar_color": null,
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "cbf1d9917e8642eea2a5a9280e6889f8": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "f998046e990941e492cfa7e2029a2a9f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "DescriptionStyleModel",
      "description_width": "",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "69f0382e202b43d682193d06842677e6": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}